<!DOCTYPE html>
<html lang="en">

<head>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66582-32"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-66582-32');
    </script>

    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Dataset Images on the Feature Store" />
<meta property="og:description" content="Example of Using a Raw Image Dataset in the Feature Store Images are often stored in binary formats for training machine learning models, such as tfrecords or parquet. However, sometimes it can be useful to store a large image dataset in a folder with one file per image, such as .jpg or .png.
This notebook will demonstrate how to create a training dataset with .jpg files in the Hopsworks Feature Store" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://examples.hopsworks.ai/featurestore/image_datasets/imagedatasetfeaturestore/" />



<meta property="article:published_time" content="2021-02-24T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2021-02-24T00:00:00&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Dataset Images on the Feature Store"/>
<meta name="twitter:description" content="Example of Using a Raw Image Dataset in the Feature Store Images are often stored in binary formats for training machine learning models, such as tfrecords or parquet. However, sometimes it can be useful to store a large image dataset in a folder with one file per image, such as .jpg or .png.
This notebook will demonstrate how to create a training dataset with .jpg files in the Hopsworks Feature Store"/>
<meta name="generator" content="Hugo 0.40.3" />

    
<script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Dataset Images on the Feature Store",
  "url": "https://examples.hopsworks.ai/featurestore/image_datasets/imagedatasetfeaturestore/",
  "wordCount": "571",
  "datePublished": "2021-02-24T00:00:00&#43;00:00",
  "dateModified": "2021-02-24T00:00:00&#43;00:00",
  "author": {
  "@type": "Person",
  "name": ""
  }
  }
</script> 

    <title>Dataset Images on the Feature Store</title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">

    
    <link href="https://examples.hopsworks.ai/css/custom.css" rel="stylesheet">
    <link href="https://examples.hopsworks.ai/css/syntax.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,500,700" rel="stylesheet">

    <link href="" rel="alternate" type="application/rss+xml" title="Hopsworks Examples" />

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

</head>

<body>

    <nav class="navbar navbar-expand-sm fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="https://examples.hopsworks.ai">Hopsworks Examples</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="nav navbar-nav mr-auto"></ul>
                <ul class="nav navbar-nav">
                    <li><a href="https://hopsworks.ai" title="Hopsworks.ai">hopsworks.ai</a></li>
                    <li><a href="https://docs.hopsworks.ai" title="Docs">docs.hopsworks.ai</a></li>
                </ul>
            </div>
        </div>
    </nav>


    
    <div class="container">
        <div class="row">
            <div class="col-sm-12">

                 


<article>
  <div class="technical_note">
    <header>
      <div class="alert alert-warning flashcard_ad" role="alert">
	Want to learn machine learning? Try my <a href="https://machinelearningflashcards.com" class="alert-link">machine learning flashcards</a>, <a href='https://amzn.to/2HwnWty' class="alert-link">book</a>, or <a href='https://www.youtube.com/channel/UCnd4Fi-ODvuPbxR2fO2j7kA' class="alert-link">study with me.</a>.
      </div>
      <h1 class="technical_note_title">Dataset Images on the Feature Store</h1>
      <div class="technical_note_date">
	<time datetime=" 2021-02-24T00:00:00Z "> 24 Feb 2021</time>
      </div>
    </header>
    <div class="content">

      

<h1 id="example-of-using-a-raw-image-dataset-in-the-feature-store">Example of Using a Raw Image Dataset in the Feature Store</h1>

<p>Images are often stored in binary formats for training machine learning models, such as tfrecords or parquet. However, sometimes it can be useful to store a large image dataset in a folder with one file per image, such as .jpg or .png.</p>

<p>This notebook will demonstrate how to create a training dataset with .jpg files in the Hopsworks Feature Store</p>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">from hops import featurestore
from hops import hdfs</code></pre></div>
<pre><code>Starting Spark application
</code></pre>

<table>
<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>18</td><td>application_1549717352737_0020</td><td>pyspark</td><td>idle</td><td><a target="_blank" href="http://hopsworks0.logicalclocks.com:8088/proxy/application_1549717352737_0020/">Link</a></td><td><a target="_blank" href="http://hopsworks0.logicalclocks.com:8042/node/containerlogs/container_e01_1549717352737_0020_01_000001/demo_featurestore_admin000__meb10000">Link</a></td><td>âœ”</td></tr></table>

<pre><code>SparkSession available as 'spark'.
</code></pre>

<h2 id="step-1-create-a-placeholder-training-dataset-from-the-featurestore-registry">Step 1: Create a PlaceHolder Training Dataset from the Featurestore Registry</h2>

<p>As a first step we can create the training dataset from the hopsworks registry UI. This will create the metadata of the training dataset and also create a folder to store the dataset in HDFS.</p>

<p><img src="./../images/image_dataset_tutorial_1.png" alt="Feature Store Image Dataset 1" title="Feature Store Image Dataset 1" /></p>

<p><img src="./../images/image_dataset_tutorial_2.png" alt="Feature Store Image Dataset 2" title="Feature Store Image Dataset 2" /></p>

<h2 id="step-2-uploading-the-images">Step 2: Uploading the Images</h2>

<p>.jpg or .png files are not designed to be written using big data tools, therefore we recommend that you upload the raw images directly from the Dataset-Service in Hopsworks.</p>

<p>The dataset will be in a folder called <code>&lt;datasetname&gt;_&lt;version&gt;</code> inside the dataset containing your training datasets (<code>&lt;projectname&gt;_&lt;Training_Datasets&gt;</code>). You can get the path directly from the API:</p>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">featurestore.get_training_dataset_path(&#34;sample_mnist&#34;)</code></pre></div>
<pre><code>'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/demo_featurestore_admin000_Training_Datasets/sample_mnist_1'
</code></pre>

<p><img src="./../images/image_dataset_tutorial_3.png" alt="Feature Store Image Dataset 3" title="Feature Store Image Dataset 3" /></p>

<p><img src="./../images/image_dataset_tutorial_4.png" alt="Feature Store Image Dataset 4" title="Feature Store Image Dataset 4" /></p>

<h2 id="step-3-read-the-training-dataset-into-a-spark-dataframe-or-a-tensorflow-dataset">Step 3: Read the Training Dataset into a Spark Dataframe or a Tensorflow Dataset</h2>

<p>Images such as .jpg or .png can be read by Spark or Tensorflow from HDFS.</p>

<h4 id="reading-an-image-dataset-with-spark">Reading an Image Dataset with Spark</h4>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">images_df = featurestore.get_training_dataset(&#34;sample_mnist&#34;)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">images_df.printSchema()</code></pre></div>
<pre><code>root
 |-- image: struct (nullable = true)
 |    |-- origin: string (nullable = true)
 |    |-- height: integer (nullable = true)
 |    |-- width: integer (nullable = true)
 |    |-- nChannels: integer (nullable = true)
 |    |-- mode: integer (nullable = true)
 |    |-- data: binary (nullable = true)
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">images_df.show(5)</code></pre></div>
<pre><code>+--------------------+
|               image|
+--------------------+
|[hdfs://10.0.2.15...|
|[hdfs://10.0.2.15...|
|[hdfs://10.0.2.15...|
|[hdfs://10.0.2.15...|
|[hdfs://10.0.2.15...|
+--------------------+
only showing top 5 rows
</code></pre>

<h4 id="reading-an-image-dataset-with-tensorflow">Reading an Image Dataset with Tensorflow</h4>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">import tensorflow as tf
import numpy as np</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">def build_tf_graph(images_dir):
    &#34;&#34;&#34;
    A simple computational graph for reading in a jpg into a tensor
    &#34;&#34;&#34;
    img_filenames = tf.gfile.Glob(images_dir + &#34;/*.jpg&#34;)
    num_images = len(img_filenames)
    img_queue = tf.train.string_input_producer(img_filenames)
    img_reader = tf.WholeFileReader()
    # Operation for reading a single file from the queue
    file_name_op, file_contents_op = img_reader.read(img_queue)
    # Operation for decoding JPEG to tensor
    img_to_tensor_op = tf.image.decode_jpeg(file_contents_op)
    return img_to_tensor_op, file_name_op, num_images</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">def run_graph_for_reading_images(sess, images_dir, num_images, img_op, file_name_op):
    &#34;&#34;&#34;
    Run the tf-graph for reading all images into tensors
    &#34;&#34;&#34;
    image_tensors = []
    image_filenames_read = []
    for i in range(num_images):
        # these two must be run in the same call to sess.run() otherwise they become unsynced which messes up labels for validation set..
        img_tensor, file_name_str = sess.run([img_op, file_name_op])
        image_tensors.append(img_tensor)
        image_filenames_read.append(file_name_str)
    return np.array(image_tensors), np.array(image_filenames_read)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">def init_graph():
    &#34;&#34;&#34; 
    Initialize the graph and variables for Tensorflow engine 
    &#34;&#34;&#34;
    # get operation for initializing the global variables in the graph
    init_g = tf.global_variables_initializer()
    
    # create a session for encapsulating the environment where 
    # operations can be run and tensors can be evaluated
    sess = tf.Session()
    
    # run the initialization operation
    sess.run(init_g)
    return sess</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">def setup_tf():
    &#34;&#34;&#34;
    Setup TF session
    &#34;&#34;&#34;
    # Initialize TF
    sess = init_graph()

    # Get coordinator for threads to be able to read
    coord = tf.train.Coordinator()

    # Starts all queue runners in the graph and return list of the threads
    threads = tf.train.start_queue_runners(coord=coord, sess=sess)
    
    return sess, coord, threads</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">images_dir = featurestore.get_training_dataset_path(&#34;sample_mnist&#34;)
img_to_tensor_op, file_name_op, num_images = build_tf_graph(images_dir)
sess, coord, threads = setup_tf()
image_tensors, image_filenames_read = run_graph_for_reading_images(sess, 
                                                                   images_dir, 
                                                                   num_images, 
                                                                   img_to_tensor_op, 
                                                                   file_name_op
                                                                  )</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">image_filenames_read</code></pre></div>
<pre><code>array([b'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/demo_featurestore_admin000_Training_Datasets/sample_mnist_1/img_4.jpg',
       b'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/demo_featurestore_admin000_Training_Datasets/sample_mnist_1/img_1.jpg',
       b'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/demo_featurestore_admin000_Training_Datasets/sample_mnist_1/img_3.jpg',
       b'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/demo_featurestore_admin000_Training_Datasets/sample_mnist_1/img_10.jpg',
       b'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/demo_featurestore_admin000_Training_Datasets/sample_mnist_1/img_2.jpg',
       b'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/demo_featurestore_admin000_Training_Datasets/sample_mnist_1/img_6.jpg',
       b'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/demo_featurestore_admin000_Training_Datasets/sample_mnist_1/img_7.jpg',
       b'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/demo_featurestore_admin000_Training_Datasets/sample_mnist_1/img_9.jpg',
       b'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/demo_featurestore_admin000_Training_Datasets/sample_mnist_1/img_8.jpg',
       b'hdfs://10.0.2.15:8020/Projects/demo_featurestore_admin000/demo_featurestore_admin000_Training_Datasets/sample_mnist_1/img_5.jpg'],
      dtype='|S128')
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">image_tensors[0].shape</code></pre></div>
<pre><code>(28, 28, 1)
</code></pre>

    </div>
    <aside>
      <div class="bug_reporting">
	<h4>Find an error or bug?</h4>
	<p>Everything on this site is available on GitHub. Head to <a href='https://github.com/chrisalbon/notes/issues/new'>and submit a suggested change</a>. Include the tutorial's URL in the issue.</p>
      </div>
    </aside>

  </div>
</article>




            </div>

        </div>
    </div>

    

    <footer class="footer text-center">
        <div class="container">
            <span class="text-muted">This project contains 59 pages and is available on <a href="https://github.com/napsterinblue/notes">GitHub</a>. Copyright &copy; NapsterInBlue, <time datetime="2018">2018</time>.</span>
        </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ"
        crossorigin="anonymous"></script>

</body>

</html>
