<!DOCTYPE html>
<html lang="en">

<head>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66582-32"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-66582-32');
    </script>

    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Inference (Batch) in PySpark Example" />
<meta property="og:description" content="Large Scale Batch Inference on HopsFS To run this notebook you must first install the following libraries in your project&rsquo;s conda environment (in addition to the base libraries):
 Pillow Matplotlib  Moreover, the notebook assumes that you have access to the ImageNet dataset, this can either be uploaded to your project or shared from another project.
You also need access to an internet connection so that the pre-trained model can be downloaded." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://examples.hopsworks.ai/ml/inference/batch_inference_imagenet_spark/" />



<meta property="article:published_time" content="2021-02-24T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2021-02-24T00:00:00&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Inference (Batch) in PySpark Example"/>
<meta name="twitter:description" content="Large Scale Batch Inference on HopsFS To run this notebook you must first install the following libraries in your project&rsquo;s conda environment (in addition to the base libraries):
 Pillow Matplotlib  Moreover, the notebook assumes that you have access to the ImageNet dataset, this can either be uploaded to your project or shared from another project.
You also need access to an internet connection so that the pre-trained model can be downloaded."/>
<meta name="generator" content="Hugo 0.40.3" />

    
<script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Inference (Batch) in PySpark Example",
  "url": "https://examples.hopsworks.ai/ml/inference/batch_inference_imagenet_spark/",
  "wordCount": "648",
  "datePublished": "2021-02-24T00:00:00&#43;00:00",
  "dateModified": "2021-02-24T00:00:00&#43;00:00",
  "author": {
  "@type": "Person",
  "name": ""
  }
  }
</script> 

    <title>Inference (Batch) in PySpark Example</title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">

    
    <link href="https://examples.hopsworks.ai/css/custom.css" rel="stylesheet">
    <link href="https://examples.hopsworks.ai/css/syntax.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,500,700" rel="stylesheet">

    <link href="" rel="alternate" type="application/rss+xml" title="Hopsworks Examples" />

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

</head>

<body>

    <nav class="navbar navbar-expand-sm fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="https://examples.hopsworks.ai">Hopsworks Examples</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="nav navbar-nav mr-auto"></ul>
                <ul class="nav navbar-nav">
                    <li><a href="https://hopsworks.ai" title="Hopsworks.ai">hopsworks.ai</a></li>
                    <li><a href="https://docs.hopsworks.ai" title="Docs">docs.hopsworks.ai</a></li>
                </ul>
            </div>
        </div>
    </nav>


    
    <div class="container">
        <div class="row">
            <div class="col-sm-12">

                 


<article>
  <div class="technical_note">
    <header>
      <div class="alert alert-warning flashcard_ad" role="alert">
	Want to learn machine learning? Try my <a href="https://machinelearningflashcards.com" class="alert-link">machine learning flashcards</a>, <a href='https://amzn.to/2HwnWty' class="alert-link">book</a>, or <a href='https://www.youtube.com/channel/UCnd4Fi-ODvuPbxR2fO2j7kA' class="alert-link">study with me.</a>.
      </div>
      <h1 class="technical_note_title">Inference (Batch) in PySpark Example</h1>
      <div class="technical_note_date">
	<time datetime=" 2021-02-24T00:00:00Z "> 24 Feb 2021</time>
      </div>
    </header>
    <div class="content">

      

<h1 id="large-scale-batch-inference-on-hopsfs">Large Scale Batch Inference on HopsFS</h1>

<p>To run this notebook you must first install the following libraries in your project&rsquo;s conda environment (in addition to the base libraries):</p>

<ul>
<li>Pillow</li>
<li>Matplotlib</li>
</ul>

<p>Moreover, the notebook assumes that you have access to the ImageNet dataset, this can either be uploaded to your project or shared from another project.</p>

<p>You also need access to an internet connection so that the pre-trained model can be downloaded.</p>

<h2 id="imports">Imports</h2>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from hops import experiment
from hops import tensorboard
from hops import featurestore
from hops import hdfs
from hops import util
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
from PIL import Image
import numpy as np
from tensorflow.keras.models import load_model
import tensorflow.keras.models
import types
import tempfile
from pyspark.sql import DataFrame, Row
import pydoop.hdfs as pydoop</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">%%local
import matplotlib.pyplot as plt
import tensorflow as tf
import pydoop.hdfs as pydoop
from hops import hdfs</code></pre></div>
<h2 id="constants">Constants</h2>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">HEIGHT =224
WIDTH = 224
BATCH_SIZE = 100
CHANNELS = 3
INPUT_SHAPE = 12288
NUM_CLASSES = 1000
NUM_PARALLEL_CALLS = 8
SAMPLE_IMAGE_DIR = pydoop.path.abspath(hdfs.project_path(&#34;labs&#34;) + &#34;/imagenet_2016/ILSVRC2016_CLS-LOC/ILSVRC/Data/CLS-LOC/train/n03617480/&#34;)
SAMPLE_IMAGE_NAME = &#34;n03617480_28686.JPEG&#34;
SAMPLE_IMAGE_PATH = SAMPLE_IMAGE_DIR + SAMPLE_IMAGE_NAME
MODEL_NAME = &#34;resnet_imagenet.h5&#34;</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">%%local
HEIGHT =224
WIDTH = 224
CHANNELS = 3
INPUT_SHAPE = 12288
NUM_CLASSES = 1000
BATCH_SIZE = 100
NUM_PARALLEL_CALLS = 8
SAMPLE_IMAGE_DIR = pydoop.path.abspath(hdfs.project_path(&#34;labs&#34;) + &#34;/imagenet_2016/ILSVRC2016_CLS-LOC/ILSVRC/Data/CLS-LOC/train/n03617480/&#34;)
SAMPLE_IMAGE_NAME = &#34;n03617480_28686.JPEG&#34;
SAMPLE_IMAGE_PATH = SAMPLE_IMAGE_DIR + SAMPLE_IMAGE_NAME
MODEL_NAME = &#34;resnet_imagenet.h5&#34;</code></pre></div>
<h2 id="load-pre-trained-resnet50-model-trained-on-imagenet-from-keras-applications">Load Pre-Trained ResNet50 Model Trained on ImageNet from Keras.applications</h2>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">def define_model():
    &#34;&#34;&#34;
    Defines the model to use for image classification
    
    Returns:
           ResNet50 model
    &#34;&#34;&#34;
    tf.keras.backend.set_learning_phase(False)
    model = ResNet50(weights=&#34;imagenet&#34;, input_shape=(HEIGHT, WIDTH, CHANNELS), classes=NUM_CLASSES)
    return model</code></pre></div>
<h2 id="save-pre-trained-model-to-hopsfs">Save Pre-Trained model to HopsFS</h2>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">def save_model(model):
    &#34;&#34;&#34;
    Save Pre-Trained ImageNet model to HDFS
    
    Args:
         :model: the pre-trained model with weights trained on imagenet
    Returns:
          The HDFS path where it is saved
    &#34;&#34;&#34;
    # save trained model
    model.save(MODEL_NAME) #Keras can&#39;t save to HDFS in the current version so save to local fs first
    hdfs.copy_to_hdfs(MODEL_NAME, hdfs.project_path() + &#34;Resources/&#34;, overwrite=True) # copy from local fs to hdfs
    model_hdfs_path = hdfs.project_path() + &#34;Resources/&#34; + MODEL_NAME
    return model_hdfs_path</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">hdfs_model_path = save_model(define_model())</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">hdfs_model_path</code></pre></div>
<pre><code>'hdfs://10.0.104.196:8020/Projects/EndToEndV2/Resources/resnet_imagenet.h5'
</code></pre>

<h2 id="load-pre-trained-model-from-hopsfs">Load Pre-Trained model From HopsFS</h2>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">local_model_path = hdfs.copy_to_local(hdfs_model_path, &#34;&#34;, overwrite=True) + MODEL_NAME</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">model = load_model(MODEL_NAME)</code></pre></div>
<h2 id="batch-inference-on-imagenet-using-spark-keras">Batch Inference on ImageNet using Spark + Keras</h2>

<h4 id="read-images-into-a-spark-dataframe">Read Images into a Spark Dataframe</h4>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.conf.set(&#34;spark.sql.files.ignoreCorruptFiles&#34;, &#34;true&#34;)
df = spark.read.option(&#34;mode&#34;, &#34;DROPMALFORMED&#34;).format(&#34;image&#34;).load(&#34;hdfs://10.0.104.196:8020/Projects/labs/imagenet_2016/ILSVRC2016_CLS-LOC/ILSVRC/Data/CLS-LOC/train/*/&#34;)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">df_filtered = df.select(&#34;image.origin&#34;)</code></pre></div>
<h4 id="count-how-many-images-to-perform-batch-inference-on">Count how many images to perform batch inference on</h4>

<p>ImageNet2016 contains 1281167 images in the training dataset.</p>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">df_filtered.count()</code></pre></div>
<pre><code>1281167
</code></pre>

<h4 id="parallel-inference-using-spark-executors">Parallel Inference using Spark Executors</h4>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">def inference_fn(partition):
    from hops import hdfs
    try:
        local_model_path = hdfs.copy_to_local(hdfs_model_path, &#34;&#34;, overwrite=True) + MODEL_NAME
        model = load_model(MODEL_NAME)
    except:
        print(&#34;could not copy model to local&#34;)
    for row in partition:
        # some rows in imagenet are malformed so we skip those
        try:
            IMAGE_NAME = row.origin.rsplit(&#39;/&#39;, 1)[1]
            local_sample_image_path = hdfs.copy_to_local(row.origin, &#34;&#34;, overwrite=True) + IMAGE_NAME
            img = image.load_img(local_sample_image_path, target_size=(HEIGHT, WIDTH))
            x = image.img_to_array(img)
            x = np.expand_dims(x, axis=0)
            x = preprocess_input(x)
            predictions = model.predict(x)
            decoded_predictions = decode_predictions(predictions, top=3)
            top_1_id = str(decoded_predictions[0][0][0])
            top_1_label = str(decoded_predictions[0][0][1])
            top_1_confidence = float(decoded_predictions[0][0][2])
            top_2_id = str(decoded_predictions[0][1][0])
            top_2_label = str(decoded_predictions[0][1][1])
            top_2_confidence = float(decoded_predictions[0][1][2])
            top_3_id = str(decoded_predictions[0][2][0])
            top_3_label = str(decoded_predictions[0][2][1])
            top_3_confidence = float(decoded_predictions[0][2][2])    
            Example = Row(&#34;image_path&#34;, &#34;top1_id&#34;, &#34;top1_label&#34;, &#34;top1_confidence&#34;, &#34;top2_id&#34;, 
                          &#34;top2_label&#34;, &#34;top2_confidence&#34;, &#34;top3_id&#34;, &#34;top3_label&#34;, &#34;top3_confidence&#34;)
            print(&#34;Labelled example successfully&#34;)
            yield Example(row.origin, top_1_id, top_1_label, top_1_confidence, top_2_id, top_2_label, top_2_confidence,
                          top_3_id, top_3_label, top_3_confidence)
        except:
            print(&#34;Failed to label row&#34;)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">labeled_df = df_filtered.limit(10000).repartition(util.num_executors()*3).rdd.mapPartitions(inference_fn).toDF()</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">labeled_df.write.mode(&#34;overwrite&#34;).parquet(hdfs.project_path() + &#34;Resources/labels.parquet&#34;)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">labeled_df.printSchema()</code></pre></div>
<pre><code>root
 |-- image_path: string (nullable = true)
 |-- top1_id: string (nullable = true)
 |-- top1_label: string (nullable = true)
 |-- top1_confidence: double (nullable = true)
 |-- top2_id: string (nullable = true)
 |-- top2_label: string (nullable = true)
 |-- top2_confidence: double (nullable = true)
 |-- top3_id: string (nullable = true)
 |-- top3_label: string (nullable = true)
 |-- top3_confidence: double (nullable = true)
</code></pre>

<h3 id="compare-prediction-against-image">Compare Prediction against Image</h3>

<p>We can do a simple test to compare an image in the dataframe against a predicted label</p>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">row = labeled_df.first()</code></pre></div>
<p>Copy the HDFS path below to the %%local cell to plot it.</p>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">row.image_path</code></pre></div>
<pre><code>'hdfs://10.0.104.196:8020/Projects/labs/imagenet_2016/ILSVRC2016_CLS-LOC/ILSVRC/Data/CLS-LOC/train/n04550184/n04550184_41732.JPEG'
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">row.top1_label</code></pre></div>
<pre><code>'wardrobe'
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">row.top2_label</code></pre></div>
<pre><code>'entertainment_center'
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">row.top3_label</code></pre></div>
<pre><code>'bookcase'
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">%%local
%matplotlib inline 
with tf.Session() as sess:
    sample_img = tf.image.decode_jpeg(tf.read_file(&#34;hdfs://10.0.104.196:8020/Projects/labs/imagenet_2016/ILSVRC2016_CLS-LOC/ILSVRC/Data/CLS-LOC/train/n04550184/n04550184_41732.JPEG&#34;)).eval()
    plt.imshow(sample_img)
    plt.show()</code></pre></div>
<p><img src="Batch_Inference_Imagenet_Spark_files/Batch_Inference_Imagenet_Spark_35_0.png" alt="png" /></p>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark"></code></pre></div>
    </div>
    <aside>
      <div class="bug_reporting">
	<h4>Find an error or bug?</h4>
	<p>Everything on this site is available on GitHub. Head to <a href='https://github.com/chrisalbon/notes/issues/new'>and submit a suggested change</a>. Include the tutorial's URL in the issue.</p>
      </div>
    </aside>

  </div>
</article>




            </div>

        </div>
    </div>

    

    <footer class="footer text-center">
        <div class="container">
            <span class="text-muted">This project contains 59 pages and is available on <a href="https://github.com/napsterinblue/notes">GitHub</a>. Copyright &copy; NapsterInBlue, <time datetime="2018">2018</time>.</span>
        </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ"
        crossorigin="anonymous"></script>

</body>

</html>
