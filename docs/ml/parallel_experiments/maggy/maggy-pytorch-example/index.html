<!DOCTYPE html>
<html lang="en">

<head>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66582-32"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-66582-32');
    </script>

    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Maggy PyTorch HParam Tuning Example" />
<meta property="og:description" content="# Start spark session print(&#39;Startup&#39;)# Import maggy, define searchspace from maggy import Searchspace sp = Searchspace(l1_size=(&#39;Integer&#39;, [2,32]), l2_size=(&#39;Integer&#39;, [2,32]), batch_size=(&#39;integer&#39;, [2,16]))# Hyperparameter tuning. Create oblivious training function. from maggy import experiment def training_function(l1_size, l2_size, batch_size, reporter): import torch import torch.nn as nn import torch.optim as optim import math # define torch model class NeuralNetwork(nn.Module): def __init__(self, l1_size, l2_size): super().__init__() self.linear1 = nn.Linear(2,l1_size) self.linear2 = nn.Linear(l1_size,l2_size) self.output = nn.Linear(l2_size, 1) def forward(self, x): x = torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://examples.hopsworks.ai/ml/parallel_experiments/maggy/maggy-pytorch-example/" />



<meta property="article:published_time" content="2021-02-24T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2021-02-24T00:00:00&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Maggy PyTorch HParam Tuning Example"/>
<meta name="twitter:description" content="# Start spark session print(&#39;Startup&#39;)# Import maggy, define searchspace from maggy import Searchspace sp = Searchspace(l1_size=(&#39;Integer&#39;, [2,32]), l2_size=(&#39;Integer&#39;, [2,32]), batch_size=(&#39;integer&#39;, [2,16]))# Hyperparameter tuning. Create oblivious training function. from maggy import experiment def training_function(l1_size, l2_size, batch_size, reporter): import torch import torch.nn as nn import torch.optim as optim import math # define torch model class NeuralNetwork(nn.Module): def __init__(self, l1_size, l2_size): super().__init__() self.linear1 = nn.Linear(2,l1_size) self.linear2 = nn.Linear(l1_size,l2_size) self.output = nn.Linear(l2_size, 1) def forward(self, x): x = torch."/>
<meta name="generator" content="Hugo 0.40.3" />

    
<script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Maggy PyTorch HParam Tuning Example",
  "url": "https://examples.hopsworks.ai/ml/parallel_experiments/maggy/maggy-pytorch-example/",
  "wordCount": "221",
  "datePublished": "2021-02-24T00:00:00&#43;00:00",
  "dateModified": "2021-02-24T00:00:00&#43;00:00",
  "author": {
  "@type": "Person",
  "name": ""
  }
  }
</script> 

    <title>Maggy PyTorch HParam Tuning Example</title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">

    
    <link href="https://examples.hopsworks.ai/css/custom.css" rel="stylesheet">
    <link href="https://examples.hopsworks.ai/css/syntax.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,500,700" rel="stylesheet">

    <link href="" rel="alternate" type="application/rss+xml" title="Hopsworks Examples" />

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

</head>

<body>

    <nav class="navbar navbar-expand-sm fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="https://examples.hopsworks.ai">Hopsworks Examples</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="nav navbar-nav mr-auto"></ul>
                <ul class="nav navbar-nav">
                    <li><a href="https://hopsworks.ai" title="Hopsworks.ai">Hopsworks</a></li>
                    <li><a href="https://docs.hopsworks.ai" title="Docs">Docs</a></li>
                </ul>
            </div>
        </div>
    </nav>


    
    <div class="container">
        <div class="row">
            <div class="col-sm-12">

                 


<article>
  <div class="technical_note">
    <header>
      <div class="alert alert-warning flashcard_ad" role="alert">
	Want to learn machine learning? Try my <a href="https://machinelearningflashcards.com" class="alert-link">machine learning flashcards</a>, <a href='https://amzn.to/2HwnWty' class="alert-link">book</a>, or <a href='https://www.youtube.com/channel/UCnd4Fi-ODvuPbxR2fO2j7kA' class="alert-link">study with me.</a>.
      </div>
      <h1 class="technical_note_title">Maggy PyTorch HParam Tuning Example</h1>
      <div class="technical_note_date">
	<time datetime=" 2021-02-24T00:00:00Z "> 24 Feb 2021</time>
      </div>
    </header>
    <div class="content">

      <div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Start spark session</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Startup&#39;</span><span class="p">)</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Import maggy, define searchspace</span>
<span class="kn">from</span> <span class="nn">maggy</span> <span class="kn">import</span> <span class="n">Searchspace</span>

<span class="n">sp</span> <span class="o">=</span> <span class="n">Searchspace</span><span class="p">(</span><span class="n">l1_size</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;Integer&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">32</span><span class="p">]),</span> <span class="n">l2_size</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;Integer&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">32</span><span class="p">]),</span> <span class="n">batch_size</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;integer&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">16</span><span class="p">]))</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Hyperparameter tuning. Create oblivious training function.</span>
<span class="kn">from</span> <span class="nn">maggy</span> <span class="kn">import</span> <span class="n">experiment</span>

<span class="k">def</span> <span class="nf">training_function</span><span class="p">(</span><span class="n">l1_size</span><span class="p">,</span> <span class="n">l2_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">reporter</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
    <span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>
    <span class="kn">import</span> <span class="nn">math</span>
        
    <span class="c1"># define torch model</span>
    <span class="k">class</span> <span class="nc">NeuralNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">l1_size</span><span class="p">,</span> <span class="n">l2_size</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">l1_size</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">l1_size</span><span class="p">,</span><span class="n">l2_size</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">l2_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            
        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
    <span class="c1"># define training parameters</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">(</span><span class="n">l1_size</span><span class="p">,</span> <span class="n">l2_size</span><span class="p">)</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="c1"># define random training data</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">train_ds</span><span class="p">,</span> <span class="n">test_ds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="mi">800</span><span class="p">,</span><span class="mi">200</span><span class="p">])</span>
    <span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">testloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">):</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="c1"># Only necessary if early stopping and live metrics are to be employed, otherwise can be omitted.</span>
            <span class="n">reporter</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">t</span><span class="o">%</span><span class="mi">25</span> <span class="o">==</span> <span class="mi">24</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&#34;Iteration {}: MSE Loss: {:.2e}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">testloader</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
            <span class="n">test_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;MSE Loss of the model: {:.2e}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>

    <span class="k">return</span> <span class="n">test_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Run the search with Maggy. </span>
<span class="n">result</span> <span class="o">=</span> <span class="n">experiment</span><span class="o">.</span><span class="n">lagom</span><span class="p">(</span><span class="n">train_fn</span><span class="o">=</span><span class="n">training_function</span><span class="p">,</span> 
                           <span class="n">searchspace</span><span class="o">=</span><span class="n">sp</span><span class="p">,</span> 
                           <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;randomsearch&#39;</span><span class="p">,</span> 
                           <span class="n">direction</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span>
                           <span class="n">num_trials</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                           <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fctApproxTest&#39;</span><span class="p">,</span> 
                           <span class="n">hb_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                           <span class="n">es_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                           <span class="n">es_min</span><span class="o">=</span><span class="mi">5</span>
                          <span class="p">)</span></code></pre></div>
    </div>
    <aside>
      <div class="bug_reporting">
	<h4>Find an error or bug?</h4>
	<p>Everything on this site is available on GitHub. Head to <a href='https://github.com/chrisalbon/notes/issues/new'>and submit a suggested change</a>. Include the tutorial's URL in the issue.</p>
      </div>
    </aside>

  </div>
</article>




            </div>

        </div>
    </div>

    

    <footer class="footer text-center">
        <div class="container">
            <span class="text-muted">There are 59 notebooks and they are available on <a href="https://github.com/logicalclocks/hops-examples">GitHub</a>. Copyright &copy; Logical Clocks AB, <time datetime="2021">2021</time>.</span>
        </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ"
        crossorigin="anonymous"></script>

</body>

</html>
