<!DOCTYPE html>
<html lang="en">

<head>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66582-32"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-66582-32');
    </script>

    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Hive PySpark Example" />
<meta property="og:description" content="PySpark With Hive In this notebook we&rsquo;ll cover how you can read/write to Hive using SparkSQL, this notebook assumes that you have enabled the service &ldquo;Hive&rdquo; in your project
Create a SparkSession with Hive Enabled sparkmagic automatically creates a spark session in the cluster for us with Hive enabled
spark Starting Spark application   IDYARN Application IDKindStateSpark UIDriver logCurrent session?0application_1540813611542_0002pysparkidleLinkLink✔ SparkSession available as &#39;spark&#39;. &lt;pyspark.sql.session.SparkSession object at 0x7f183f464860&gt;  Select Hive Database Using the spark session you can interact with Hive through the sql method on the sparkSession, or through auxillary methods likes ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://examples.hopsworks.ai/spark/pysparkwithhive/" />



<meta property="article:published_time" content="2021-02-24T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2021-02-24T00:00:00&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Hive PySpark Example"/>
<meta name="twitter:description" content="PySpark With Hive In this notebook we&rsquo;ll cover how you can read/write to Hive using SparkSQL, this notebook assumes that you have enabled the service &ldquo;Hive&rdquo; in your project
Create a SparkSession with Hive Enabled sparkmagic automatically creates a spark session in the cluster for us with Hive enabled
spark Starting Spark application   IDYARN Application IDKindStateSpark UIDriver logCurrent session?0application_1540813611542_0002pysparkidleLinkLink✔ SparkSession available as &#39;spark&#39;. &lt;pyspark.sql.session.SparkSession object at 0x7f183f464860&gt;  Select Hive Database Using the spark session you can interact with Hive through the sql method on the sparkSession, or through auxillary methods likes ."/>
<meta name="generator" content="Hugo 0.40.3" />

    
<script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Hive PySpark Example",
  "url": "https://examples.hopsworks.ai/spark/pysparkwithhive/",
  "wordCount": "538",
  "datePublished": "2021-02-24T00:00:00&#43;00:00",
  "dateModified": "2021-02-24T00:00:00&#43;00:00",
  "author": {
  "@type": "Person",
  "name": ""
  }
  }
</script> 

    <title>Hive PySpark Example</title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">

    
    <link href="https://examples.hopsworks.ai/css/custom.css" rel="stylesheet">
    <link href="https://examples.hopsworks.ai/css/syntax.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,500,700" rel="stylesheet">

    <link href="" rel="alternate" type="application/rss+xml" title="Hopsworks Examples" />

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

</head>

<body>

    <nav class="navbar navbar-expand-sm fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="https://examples.hopsworks.ai">Hopsworks Examples</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="nav navbar-nav mr-auto"></ul>
                <ul class="nav navbar-nav">
                    <li><a href="https://hopsworks.ai" title="Hopsworks.ai">hopsworks.ai</a></li>
                    <li><a href="https://docs.hopsworks.ai" title="Docs">docs.hopsworks.ai</a></li>
                </ul>
            </div>
        </div>
    </nav>


    
    <div class="container">
        <div class="row">
            <div class="col-sm-12">

                 


<article>
  <div class="technical_note">
    <header>
      <div class="alert alert-warning flashcard_ad" role="alert">
	Want to learn machine learning? Try my <a href="https://machinelearningflashcards.com" class="alert-link">machine learning flashcards</a>, <a href='https://amzn.to/2HwnWty' class="alert-link">book</a>, or <a href='https://www.youtube.com/channel/UCnd4Fi-ODvuPbxR2fO2j7kA' class="alert-link">study with me.</a>.
      </div>
      <h1 class="technical_note_title">Hive PySpark Example</h1>
      <div class="technical_note_date">
	<time datetime=" 2021-02-24T00:00:00Z "> 24 Feb 2021</time>
      </div>
    </header>
    <div class="content">

      

<h1 id="pyspark-with-hive">PySpark With Hive</h1>

<p>In this notebook we&rsquo;ll cover how you can read/write to Hive using SparkSQL, this notebook assumes that you have enabled the service &ldquo;Hive&rdquo; in your project</p>

<h2 id="create-a-sparksession-with-hive-enabled">Create a SparkSession with Hive Enabled</h2>

<p>sparkmagic automatically creates a spark session in the cluster for us with Hive enabled</p>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark</code></pre></div>
<pre><code>Starting Spark application
</code></pre>

<table>
<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1540813611542_0002</td><td>pyspark</td><td>idle</td><td><a target="_blank" href="http://hopsworks0.logicalclocks.com:8088/proxy/application_1540813611542_0002/">Link</a></td><td><a target="_blank" href="http://hopsworks0.logicalclocks.com:8042/node/containerlogs/container_e01_1540813611542_0002_01_000001/test__meb10000">Link</a></td><td>✔</td></tr></table>

<pre><code>SparkSession available as 'spark'.
&lt;pyspark.sql.session.SparkSession object at 0x7f183f464860&gt;
</code></pre>

<h2 id="select-hive-database">Select Hive Database</h2>

<p>Using the spark session you can interact with Hive through the <code>sql</code> method on the sparkSession, or through auxillary methods likes <code>.select()</code> and <code>.where()</code>.</p>

<p>Each project that have enabled Hive will automatically have a Hive database created for them, this is the only Hive database that you can access unless someone have shared their database with you.</p>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">from hops import hdfs as hopsfs
PROJECT_NAME = hopsfs.project_name()</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">PROJECT_NAME</code></pre></div>
<pre><code>'test'
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;use &#34; + PROJECT_NAME)</code></pre></div>
<pre><code>DataFrame[]
</code></pre>

<h2 id="create-tables">Create Tables</h2>

<p>Tables can be created either by issuing a <code>CREATE TABLE</code> statement or by using the <code>saveAsTable()</code> method on an existing dataframe. When using <code>saveAsTable</code> spark will infer the schema from the dataframe and do the <code>CREATE TABLE</code> for you.</p>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;show tables&#34;).show()</code></pre></div>
<pre><code>+--------+---------+-----------+
|database|tableName|isTemporary|
+--------+---------+-----------+
+--------+---------+-----------+
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;CREATE TABLE MAGIC_MATRIX (position int, value float) STORED AS ORC&#34;)</code></pre></div>
<pre><code>DataFrame[]
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;show tables&#34;).show()</code></pre></div>
<pre><code>+--------+------------+-----------+
|database|   tableName|isTemporary|
+--------+------------+-----------+
|    test|magic_matrix|      false|
+--------+------------+-----------+
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">from pyspark.sql.types import *
schema = StructType([StructField(&#39;SquaredValue&#39;, IntegerType(), True)])</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">from pyspark.sql import SQLContext
sqlContext = SQLContext(spark.sparkContext)
rddValues = spark.sparkContext.parallelize(list(range(0,100))).map(lambda x: [x*x])
dfValues = sqlContext.createDataFrame(rddValues,schema)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">dfValues.show(5)</code></pre></div>
<pre><code>+------------+
|SquaredValue|
+------------+
|           0|
|           1|
|           4|
|           9|
|          16|
+------------+
only showing top 5 rows
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">dfValues.write.format(&#34;ORC&#34;).mode(&#34;overwrite&#34;).saveAsTable(&#34;SquaredValues&#34;)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;show tables&#34;).show()</code></pre></div>
<pre><code>+--------+-------------+-----------+
|database|    tableName|isTemporary|
+--------+-------------+-----------+
|    test| magic_matrix|      false|
|    test|squaredvalues|      false|
+--------+-------------+-----------+
</code></pre>

<h2 id="insert-values">Insert Values</h2>

<p>Values can be inserted with plain SQL or by using <code>saveAsTable</code> / <code>insertInto</code></p>

<h3 id="simple-insert">Simple Insert</h3>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;INSERT INTO TABLE magic_matrix VALUES (1, 99), (2, 100)&#34;)</code></pre></div>
<pre><code>DataFrame[]
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SELECT * FROM magic_matrix&#34;).show()</code></pre></div>
<pre><code>+--------+-----+
|position|value|
+--------+-----+
|       1| 99.0|
|       2|100.0|
+--------+-----+
</code></pre>

<h3 id="insert-with-saveastable">Insert  with saveAsTable</h3>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">rddValues2 = spark.sparkContext.parallelize(list(range(100,200))).map(lambda x: [x*x])
dfValues2 = sqlContext.createDataFrame(rddValues2,schema)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SELECT COUNT(*) FROM squaredvalues&#34;).show()</code></pre></div>
<pre><code>+--------+
|count(1)|
+--------+
|     100|
+--------+
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">dfValues2.write.format(&#34;ORC&#34;).mode(&#34;append&#34;).saveAsTable(&#34;squaredvalues&#34;)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SELECT COUNT(*) FROM squaredvalues&#34;).show()</code></pre></div>
<pre><code>+--------+
|count(1)|
+--------+
|     200|
+--------+
</code></pre>

<h2 id="insert-with-insertinto">Insert with insertInto</h2>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">dfValues2.write.mode(&#34;append&#34;).insertInto(&#34;squaredvalues&#34;)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SELECT COUNT(*) FROM squaredvalues&#34;).show()</code></pre></div>
<pre><code>+--------+
|count(1)|
+--------+
|     300|
+--------+
</code></pre>

<p>You can also use overwrite mode:</p>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">dfValues2.write.format(&#34;ORC&#34;).mode(&#34;overwrite&#34;).saveAsTable(&#34;squaredvalues&#34;)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;REFRESH TABLE squaredvalues&#34;)
spark.sql(&#34;SELECT COUNT(*) FROM squaredvalues&#34;).show()</code></pre></div>
<pre><code>+--------+
|count(1)|
+--------+
|     100|
+--------+
</code></pre>

<h3 id="insert-by-using-temptable">Insert by using TempTable</h3>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">rddValues3 = spark.sparkContext.parallelize(list(range(200,300))).map(lambda x: [x*x])
dfValues3 = sqlContext.createDataFrame(rddValues3,schema)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SELECT COUNT(*) FROM squaredvalues&#34;).show()</code></pre></div>
<pre><code>+--------+
|count(1)|
+--------+
|     200|
+--------+
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">dfValues3.registerTempTable(&#34;temptable&#34;)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">sqlContext.sql(&#34;insert into table squaredvalues select * from temptable&#34;)</code></pre></div>
<pre><code>DataFrame[]
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SELECT COUNT(*) FROM squaredvalues&#34;).show()</code></pre></div>
<pre><code>+--------+
|count(1)|
+--------+
|     300|
+--------+
</code></pre>

<h2 id="queries">Queries</h2>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SELECT * FROM squaredvalues WHERE squaredvalue &gt; 380 &#34;).show()</code></pre></div>
<pre><code>+------------+
|SquaredValue|
+------------+
|       40000|
|       40401|
|       40804|
|       41209|
|       41616|
|       42025|
|       42436|
|       42849|
|       43264|
|       43681|
|       44100|
|       44521|
|       44944|
|       45369|
|       45796|
|       46225|
|       46656|
|       47089|
|       47524|
|       47961|
+------------+
only showing top 20 rows
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SELECT * FROM magic_matrix WHERE position = 2 &#34;).show()</code></pre></div>
<pre><code>+--------+-----+
|position|value|
+--------+-----+
|       2|100.0|
+--------+-----+
</code></pre>

<h2 id="drop-tables">Drop Tables</h2>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SHOW TABLES&#34;).show()</code></pre></div>
<pre><code>+--------------+-------------+-----------+
|      database|    tableName|isTemporary|
+--------------+-------------+-----------+
|sparksqlonhive| magic_matrix|      false|
|sparksqlonhive|squaredvalues|      false|
|              |    temptable|       true|
+--------------+-------------+-----------+
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;DROP TABLE magic_matrix&#34;)</code></pre></div>
<pre><code>DataFrame[]
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SHOW TABLES&#34;).show()</code></pre></div>
<pre><code>+--------------+-------------+-----------+
|      database|    tableName|isTemporary|
+--------------+-------------+-----------+
|sparksqlonhive|squaredvalues|      false|
|              |    temptable|       true|
+--------------+-------------+-----------+
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;DROP TABLE squaredvalues&#34;)</code></pre></div>
<pre><code>DataFrame[]
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SHOW TABLES&#34;).show()</code></pre></div>
<pre><code>+--------+---------+-----------+
|database|tableName|isTemporary|
+--------+---------+-----------+
|        |temptable|       true|
+--------+---------+-----------+
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.catalog.dropTempView(&#34;temptable&#34;)</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark">spark.sql(&#34;SHOW TABLES&#34;).show()</code></pre></div>
<pre><code>+--------+---------+-----------+
|database|tableName|isTemporary|
+--------+---------+-----------+
+--------+---------+-----------+
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-pyspark" data-lang="pyspark"></code></pre></div>
    </div>
    <aside>
      <div class="bug_reporting">
	<h4>Find an error or bug?</h4>
	<p>Everything on this site is available on GitHub. Head to <a href='https://github.com/chrisalbon/notes/issues/new'>and submit a suggested change</a>. Include the tutorial's URL in the issue.</p>
      </div>
    </aside>

  </div>
</article>




            </div>

        </div>
    </div>

    

    <footer class="footer text-center">
        <div class="container">
            <span class="text-muted">This project contains 59 pages and is available on <a href="https://github.com/napsterinblue/notes">GitHub</a>. Copyright &copy; NapsterInBlue, <time datetime="2018">2018</time>.</span>
        </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ"
        crossorigin="anonymous"></script>

</body>

</html>
