{"cells":[{"cell_type":"markdown","source":["### Connect and use Hopsworks Feature Store from Databricks\n\nThis notebook assumes that you have alreadly followed the instructions in the `Databricks-FeatureStore-Setup` notebook. In particular you should have already run the `setup_databricks` method and configured the cluster with the additional Spark Settings and Init Script.\n\nBefore being able to read/write into the Hopsworks Feature Store we need to connect to it. The connection parameters are the same of the `setup_databricks` method. As before, if you don't have access to the Secrets Manager or Parameter Store, you have the option of writing the API key on a file and pass the `api_key_file` parameter."],"metadata":{}},{"cell_type":"code","source":["from  hops import featurestore\n\nfeaturestore.connect(host=\"instance.aws.hopsworks.ai\", project_name=\"demo_featurestore_admin000\", region_name=\"us-west-2\", secrets_store=\"secretsmanager\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["Once the connection has been established correctly we can start using the Hops Python API to interact with the Hopsworks Feature Store. You can find the API documentation at http://hops-py.logicalclocks.com. You can also run all the PySpark example you can find in our `hops-examples` Github repository: https://github.com/logicalclocks/hops-examples/tree/master/notebooks/featurestore - Just make sure you prepend the `featurestore.connect` method, before running any of the cells.\n\nIn the next cell we are going to demonstrate how you can use the Hops Python API to read an existing feature group and create a new one."],"metadata":{}},{"cell_type":"code","source":["attendances_features = featurestore.get_featuregroup(\"attendances_features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Running sql: use demo_featurestore_fabio000_featurestore against offline feature store\nSQL string for the query created successfully\nRunning sql: SELECT * FROM attendances_features_1 against offline feature store\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["attendances_features.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------------------+--------------+\nteam_id|average_attendance|sum_attendance|\n+-------+------------------+--------------+\n      6|         19595.973|     391919.47|\n     16|          6462.462|     129249.24|\n     20|          7226.672|     144533.44|\n     40|         3189.8455|      63796.91|\n      9|          9405.213|     188104.27|\n+-------+------------------+--------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["For the sake of the example, let's add another column to the dataframe which will become the content for a new feature group."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import rand\nnew_fg = attendances_features.withColumn(\"avg_age\", rand() * 100)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["Using the Hops Python API we can now write into the Hopsworks Feature Store the new Feature Group."],"metadata":{}},{"cell_type":"code","source":["featurestore.create_featuregroup(\n    new_fg,\n    \"attendances_features_databricks\",\n    description=\"Feature Group containing average attendances features created from Databricks\",\n    descriptive_statistics=True,\n    feature_correlation=True,\n    feature_histograms=True,\n    cluster_analysis=True\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">computing descriptive statistics for : attendances_features_databricks, version: 1\ncomputing feature correlation for: attendances_features_databricks, version: 1\ncomputing feature histograms for: attendances_features_databricks, version: 1\ncomputing cluster analysis for: attendances_features_databricks, version: 1\n/databricks/spark/python/pyspark/sql/dataframe.py:2160: UserWarning: toPandas attempted Arrow optimization because &#39;spark.sql.execution.arrow.enabled&#39; is set to true; however, failed by the reason below:\n  Unsupported type in conversion to Arrow: VectorUDT\nAttempting non-optimization as &#39;spark.sql.execution.arrow.fallback.enabled&#39; is set to true.\n  warnings.warn(msg)\nRegistering feature metadata...\nRegistering feature metadata... [COMPLETE]\nWriting feature data to offline feature group (Hive)...\nRunning sql: use demo_featurestore_fabio000_featurestore against offline feature store\nWriting feature data to offline feature group (Hive)... [COMPLETE]\nFeature group created successfully\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":10}],"metadata":{"name":"Databricks-FeatureStore","notebookId":1218182466500371},"nbformat":4,"nbformat_minor":0}
