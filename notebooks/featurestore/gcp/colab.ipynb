{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c7cb4d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Colab Hopsworks Feature Store Tour\"\n",
    "date: 2021-02-24\n",
    "type: technical_note\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hsfs[hive] -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a341472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hsfs\n",
    "\n",
    "# TODO: replace the values below: [UUID], [project-name], [api-key]\n",
    "connection = hsfs.connection(host=\"[UUID].cloud.hopsworks.ai\",\n",
    "    project=\"[project-name]\",\n",
    "    engine=\"hive\",\n",
    "    api_key_value=\"[api-key]\")\n",
    "\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073756a",
   "metadata": {},
   "source": [
    "## Show the first 5 rows in the Demo Feature Group\n",
    "\n",
    "First run the \"Feature Store Tour\" in Hopsworks to create the demo Feature Store project.\n",
    "\n",
    "A feature group is a set of related `features`. A feature is a data point that helps make predictions. A feature data value (or point) is often either a number (scalar, vector, etc) or a boolean or enum or string (categorical value).  If you are a data engineer, think of features in feature groups as columns in a database. If you are a data scientist, think of features in feature groups as columns in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0923c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_features = fs.get_feature_group(\"teams_features\",version=1)\n",
    "teams_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41acd71c",
   "metadata": {},
   "source": [
    "## Ingest some features into the Feature Store as a Feature Group\n",
    "The date we will ingest looks as follows:\n",
    "\n",
    " * first_name : string (categorical value)\n",
    " * last_name : string (categorical value)\n",
    " * country : string (categorical value)\n",
    " \n",
    " We want to use these features later to predict the country a first_name,last_name pair come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcdf145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    name_country_fg = fs.get_feature_group(name=\"name_country_fg\",version=1)\n",
    "except Exception as e: \n",
    "    url = \"https://repo.hops.works/dev/jdowling/data_cleaned_train.csv\"\n",
    "    df = pd.read_csv(url, sep=\";\")\n",
    "    name_country_fg = fs.create_feature_group(name=\"name_country_fg\",\n",
    "                                    version=1,\n",
    "                                    primary_key=['first_name', 'last_name'],\n",
    "                                    description=\"Name - Country prediction\",\n",
    "                                    validation_type=\"STRICT\",\n",
    "                                    time_travel_format=\"HUDI\",\n",
    "                                    online_enabled=True,                                        \n",
    "                                    statistics_config=True)\n",
    "    name_country_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56797b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Name: {}\".format(name_country_fg.name))\n",
    "print(\"Description: {}\".format(name_country_fg.description))\n",
    "print(\"Features:\")\n",
    "features = name_country_fg.features\n",
    "for feature in features:\n",
    "    print(\"{:<60} \\t Primary: {} \\t Partition: {}\".format(feature.name, feature.primary, feature.partition))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffbc354",
   "metadata": {},
   "source": [
    "## Feature Data Validation\n",
    "\n",
    "Garbage in, garbage out.\n",
    "\n",
    "Let's check for garbage in. If you ingest names from more than 195 countries, it's garbage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a05935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsfs.rule import Rule\n",
    "rules = connection.get_rules()\n",
    "[print(rule.to_dict()) for rule in rules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation_countries = fs.create_expectation(\"countries\",\n",
    "                                          description=\"min and max number of countries\",\n",
    "                                          features=[\"country\"], \n",
    "                                          rules=[Rule(name=\"HAS_NUMBER_OF_DISTINCT_VALUES\", level=\"ERROR\", min=1), \n",
    "                                                 Rule(name=\"HAS_NUMBER_OF_DISTINCT_VALUES\", level=\"ERROR\", max=195)])\n",
    "expectation_countries.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_country_fg.attach_expectation(expectation_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ea892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Dataframe and ingest its features into a feature group that you create here.  \n",
    "import pandas as pd \n",
    "columns = ['first_name', 'last_name', 'country']\n",
    "data = [['tom', 'johnson', 'UK'], ['penelope', 'charles', 'UK'], ['harry', 'windsor', \"USA\"]]   \n",
    "df = pd.DataFrame(data, columns=columns) \n",
    "name_country_fg.insert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b0d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = name_country_fg.get_expectations()\n",
    "[print(exp.description) for exp in exps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_validations = name_country_fg.get_validations()\n",
    "[print(validation.to_dict()) for validation in fg_validations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e0ffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            first_name  \\\n",
      "0    VRE1CIFZ3TVAPUTXD3SZBRT5F8TORU1G4QRU4ASWVA3NOQ...   \n",
      "1    WGBN6225ML0E1EVBVEC9QK24YF5M7H5X48UEMJDFUP9MZI...   \n",
      "2    VWC1JGD3RCM0RLE7Q4R48AW1PLTFAV4MNRYMUVTOIQRYJR...   \n",
      "3    MZXVS9DIDHG4LQCYQQR705PYS9DY959ZQ0E71JG8MTGHJU...   \n",
      "4    91ZY2Y6K2FJFFEB745UBUG6099ISSGEYLY1JDTEKTRRM7M...   \n",
      "..                                                 ...   \n",
      "195  JK91GNOUIXLXVZ2UVKUKBEEREPDT9RX6LSSBDYGYR1VIE4...   \n",
      "196  MYENROCDXE1O0REIRG6YE17F6OVXZZVLQYHLXP39CUGW79...   \n",
      "197  84RV7XECJWAXPERR6VIPPB6K1LN01LIG5IRP00T2ENSGLZ...   \n",
      "198  4Y9VAHZHG3ERJ5ZJSY5K0ROOAIVU6YSQR66RP1WPKVMWHN...   \n",
      "199  DZ4LKITDNFWDRB5X1KFBASDL74XA5VSPMF7CGQGZUIUTV5...   \n",
      "\n",
      "                                             last_name  \\\n",
      "0    PGAJWUP5RVF4RZCG6SN9DQ88ST5H629H24SP1B4RTJ4AF9...   \n",
      "1    WAXG3OMOS15MQAH1L81Y7573VW5ITNLC8AT91CGGZK8M96...   \n",
      "2    RKJTQPPW65EKT3CL0ZQS32ITRAJVGI4EK3795AROT78BXX...   \n",
      "3    DAL2W7CKMZ0W3DQW7WYDT5O8JM8GDD7K90OEIM034ABEHS...   \n",
      "4    HU8S30A87QRDPXZMI7GW9POKKPW5I9U7U1DW7VOL1G837S...   \n",
      "..                                                 ...   \n",
      "195  8P1Y3A730QDTCWDT9UM8SE5FA5VT4DB348OSZ8AMDCTQSW...   \n",
      "196  X90JDCMJ1PBIYI1VM4DYJDV1FTHNEFYSW14118UROR6TAO...   \n",
      "197  7FEZW65T58CEZXSXIFHJ3B3ECZNIAZQ6L7O8VUG40GQPSM...   \n",
      "198  8N4Q93539TX6PRGLN4PXET7C37BTW74XOJTJLAOZEY3W6S...   \n",
      "199  4O1Q952PG5MSW3R05T3XUFOPEWGFBYEN1SOKS0PWNJRV8M...   \n",
      "\n",
      "                                               country  \n",
      "0    64EWMXYWH4P1SWWE1AOEUMT358KT03JHMF1J1CGXJQLFNN...  \n",
      "1    GC44G3HCSZZFQWTNNM6PSXE084BG8T4D3SC1G42DIOAVPS...  \n",
      "2    2ZES14RFMY3GQD36DC2SE69PDY34E5M7D4RCT0JPCU5V7E...  \n",
      "3    JNVS6PY6ERUKF7O4TRQF6C14UWPBGENWE126I9QTPUN23Q...  \n",
      "4    B57MZJFLM4JDP4N5IQAK7NFUOTISMX2JHGZOGFLVAN17YJ...  \n",
      "..                                                 ...  \n",
      "195  320PMLAKU3AKVXE8SXHRY47LKL9J07RMBNXBMMFWEMGCP6...  \n",
      "196  JJOAIDSSH11TWZ62YF6ZKQNTSTMFWA1MHHOB07OEQ24OUJ...  \n",
      "197  O85XT445TURV0EFLX0H2K2IQ2GNYSZPC0Y978LQIF8QDTK...  \n",
      "198  H1NE72DQMRN3N6P4DIM4P2XXVQ5NZUPLBO5XCRCKSTDYTF...  \n",
      "199  Y4WJO62ALCUE37U5XLTS9NKGXX4W41L6THP9A2CPRPQTLT...  \n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "def id_generator(size=1500, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "num_rows = 600\n",
    "data = np.array([id_generator() for i in range(num_rows)]).reshape(200,3)\n",
    "df2 = pd.DataFrame(data, columns=columns)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_country_fg.insert(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_validations = name_country_fg.get_validations()\n",
    "[print(validation.to_dict()) for validation in fg_validations]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
