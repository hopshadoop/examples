{
 "cells": [
  {
   "cell_type": "raw",
   "id": "satisfactory-lucas",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Google Colab ML Feature Store Tour\"\n",
    "date: 2021-02-24\n",
    "type: technical_note\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hsfs[hive] -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hsfs\n",
    "\n",
    "# TODO: replace the values below: [UUID], [project-name], [api-key]\n",
    "connection = hsfs.connection(host=\"[UUID].cloud.hopsworks.ai\",\n",
    "    project=\"[project-name]\",\n",
    "    engine=\"hive\",\n",
    "    api_key_value=\"[api-key]\")\n",
    "\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-dakota",
   "metadata": {},
   "source": [
    "## Show the first 5 rows in a Feature Group\n",
    "A feature group is a set of related `features`. A feature is a data point that helps make predictions. A feature data value (or point) is often either a number (scalar, vector, etc) or a boolean or enum or string (categorical value).  If you are a data engineer, think of features in feature groups as columns in a database. If you are a data scientist, think of features in feature groups as columns in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_features = fs.get_feature_group(\"teams_features\",version=1)\n",
    "teams_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-outside",
   "metadata": {},
   "source": [
    "## Ingest some features into the Feature Store as a Feature Group\n",
    "The date we will ingest looks as follows:\n",
    "\n",
    " * first_name : string (categorical value)\n",
    " * last_name : string (categorical value)\n",
    " * country : string (categorical value)\n",
    " \n",
    " We want to use these features later to predict the country a first_name,last_name pair come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    name_country_fg = fs.get_feature_group(name=\"name_country_fg\",version=1)\n",
    "except Exception as e: \n",
    "    url = \"https://repo.hops.works/dev/jdowling/data_cleaned_train.csv\"\n",
    "    df = pd.read_csv(url, sep=\";\")\n",
    "    name_country_fg = fs.create_feature_group(name=\"name_country_fg\",\n",
    "                                    version=1,\n",
    "                                    primary_key=['first_name', 'last_name'],\n",
    "                                    description=\"Name - Country prediction\",\n",
    "                                    validation_type=\"STRICT\",\n",
    "                                    time_travel_format=\"HUDI\",\n",
    "                                    online_enabled=True,                                        \n",
    "                                    statistics_config=True)\n",
    "    name_country_fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Name: {}\".format(name_country_fg.name))\n",
    "print(\"Description: {}\".format(name_country_fg.description))\n",
    "print(\"Features:\")\n",
    "features = name_country_fg.features\n",
    "for feature in features:\n",
    "    print(\"{:<60} \\t Primary: {} \\t Partition: {}\".format(feature.name, feature.primary, feature.partition))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-disco",
   "metadata": {},
   "source": [
    "## Feature Data Validation\n",
    "\n",
    "Garbage in, garbage out.\n",
    "\n",
    "Let's check for garbage in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsfs.rule import Rule\n",
    "rules = connection.get_rules()\n",
    "[print(rule.to_dict()) for rule in rules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation_countries = fs.create_expectation(\"countries\",\n",
    "                                          description=\"min and max number of countries\",\n",
    "                                          features=[\"country\"], \n",
    "                                          rules=[Rule(name=\"HAS_NUMBER_OF_DISTINCT_VALUES\", level=\"ERROR\", min=1), \n",
    "                                                 Rule(name=\"HAS_NUMBER_OF_DISTINCT_VALUES\", level=\"ERROR\", max=195)])\n",
    "expectation_countries.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_country_fg.attach_expectation(expectation_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Dataframe and ingest its features into a feature group that you create here.  \n",
    "import pandas as pd \n",
    "columns = ['first_name', 'last_name', 'country']\n",
    "data = [['tom', 'johnson', 'UK'], ['penelope', 'charles', 'UK'], ['harry', 'windsor', \"USA\"]]   \n",
    "df = pd.DataFrame(data, columns=columns) \n",
    "name_country_fg.insert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = name_country_fg.get_expectations()\n",
    "[print(exp.description) for exp in exps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_validations = name_country_fg.get_validations()\n",
    "[print(validation.to_dict()) for validation in fg_validations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "def id_generator(size=1500, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "num_rows = 600\n",
    "\n",
    "data = np.array([id_generator() for i in range(num_rows)]).reshape(200,3)\n",
    "df2 = pd.DataFrame(data, columns=columns)\n",
    "name_country_fg.insert(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_validations = name_country_fg.get_validations()\n",
    "[print(validation.to_dict()) for validation in fg_validations]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
