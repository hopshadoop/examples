{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9f335f45-d61f-4341-b9eb-993b5743a2cb",
     "showTitle": false,
     "title": ""
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "title: \"Maggy Distributed Training with Tensorflow example\"\n",
    "date: 2021-05-03\n",
    "type: technical_note\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Maggy enables you to train with Tensorflow distributed optimizers.\n",
    "Using Maggy, you have to make minimal changes in train your model in a distributed fashion."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cd1d717a-dce6-48fc-b33c-b62ee62bf262",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 0. Spark Session\n",
    "\n",
    "Make sure you have a running Spark Session/Context available.\n",
    "\n",
    "On Hopsworks, just run your notebook to start the spark application.\n",
    "\n",
    "### 1. Model definition\n",
    "\n",
    "Let's define the model we want to train. The layers of the model have to be defined in the \\_\\_init__ function.\n",
    "\n",
    "Do not instantiate the class, otherwise you won't be able to use Maggy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "17b233a3-1b0f-470d-8e39-579b238efb47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type bytes)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-8a0dd646cc59>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0msp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSparkSession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilder\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;34m.\u001B[0m\u001B[0mmaster\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"local\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;34m.\u001B[0m\u001B[0mappName\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"f-mnist-maggy\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"spark.dynamicAllocation.enabled\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"true\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/pyspark/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconf\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mSparkConf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontext\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mSparkContext\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrdd\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mRDD\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mRDDBarrier\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfiles\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mSparkFiles\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/pyspark/context.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mPy4JError\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0maccumulators\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccumulators\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mAccumulator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbroadcast\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mBroadcast\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBroadcastPickleRegistry\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/pyspark/accumulators.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     95\u001B[0m     \u001B[0;32mimport\u001B[0m \u001B[0msocketserver\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mSocketServer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mthreading\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 97\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mserializers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mread_int\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPickleSerializer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     98\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     99\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/pyspark/serializers.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     70\u001B[0m     \u001B[0mxrange\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcloudpickle\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     73\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_exception_message\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/pyspark/cloudpickle.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 145\u001B[0;31m \u001B[0m_cell_set_template_code\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_make_cell_set_template_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/pyspark/cloudpickle.py\u001B[0m in \u001B[0;36m_make_cell_set_template_code\u001B[0;34m()\u001B[0m\n\u001B[1;32m    124\u001B[0m         )\n\u001B[1;32m    125\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 126\u001B[0;31m         return types.CodeType(\n\u001B[0m\u001B[1;32m    127\u001B[0m             \u001B[0mco\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mco_argcount\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    128\u001B[0m             \u001B[0mco\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mco_kwonlyargcount\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: an integer is required (got type bytes)"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "sp = pyspark.sql.SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"f-mnist-maggy\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.executor.cores\", 4) \\\n",
    "    .config(\n",
    "    \"spark.dynamicAllocation.minExecutors\",\"1\") \\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\",\"5\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e86b1d9b-6989-4bc1-a5c9-377fae70b928",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# you can use keras.Sequential(), you just need to override it \n",
    "# on a custom class and define the layers in __init__()\n",
    "class NeuralNetwork(Sequential):\n",
    "        \n",
    "    def __init__(self, nl=4):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.add(Dense(10,input_shape=(None,4),activation='tanh'))\n",
    "        if nl >= 4:\n",
    "          for i in range(0, nl-2):\n",
    "            self.add(Dense(8,activation='tanh'))\n",
    "        self.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model = NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ddede077-fba9-4e02-bce0-b58076b9c7fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Dataset creation\n",
    "\n",
    "You can create the dataset here and pass it to the TfDistributedConfig, or creating it in the training function.\n",
    "\n",
    "You need to change the dataset path is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f6d9d56a-32f1-4f3a-b1a2-75c9fb2fa799",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_set_path = \"/Users/riccardo/Downloads/iris_train.csv\"\n",
    "test_set_path = \"/Users/riccardo/Downloads/iris_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2be3e022-ce78-432a-b454-fadcab65cfbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_set = sp.read.format(\"csv\").option(\"header\",\"true\")\\\n",
    "  .option(\"inferSchema\", \"true\").load(train_set_path).drop('_c0')\n",
    "\n",
    "test_set = sp.read.format(\"csv\").option(\"header\",\"true\")\\\n",
    "  .option(\"inferSchema\", \"true\").load(test_set_path).drop('_c0')\n",
    "\n",
    "raw_train_set = train_set.toPandas().values\n",
    "raw_test_set = test_set.toPandas().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a9e43e01-48f9-40ec-9290-d2fc091958ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_data(train_set, test_set):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train = train_set[:,0:4]\n",
    "    y_train = train_set[:,4:]\n",
    "    X_test = test_set[:,0:4]\n",
    "    y_test = test_set[:,4:]\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "  \n",
    "train_set, test_set = process_data(raw_train_set, raw_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "75fd09d0-ae37-45ee-837d-5c509d96953c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Defining the training function\n",
    "\n",
    "The programming model is that you wrap the code containing the model training inside a wrapper function. Inside that wrapper function provide all imports and parts that make up your experiment.\n",
    "\n",
    "The function should return the metric that you want to optimize for. This should coincide with the metric being reported in the Keras callback (see next point).\n",
    "You can return the metric list, in this case only the loss element will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "31c9de50-b0fa-4c2e-a006-5789584c93ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def hpo_function(number_layers, reporter):\n",
    "  \n",
    "  model = NeuralNetwork(nl=number_layers)\n",
    "  model.build()\n",
    "  \n",
    "  #fitting the model and predicting\n",
    "  model.compile(Adam(lr=0.04),'categorical_crossentropy',metrics=['accuracy'])\n",
    "  train_input, test_input = process_data(raw_train_set, raw_test_set)\n",
    "\n",
    "  train_batch_size = 75\n",
    "  test_batch_size = 15\n",
    "  epochs = 10\n",
    "  \n",
    "  model.fit(x=train_input[0], y=train_input[1],\n",
    "            batch_size=train_batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1)\n",
    "\n",
    "  score = model.evaluate(x=test_input[0], y=test_input[1], batch_size=test_batch_size, verbose=1)\n",
    "                         \n",
    "  print(f'Test loss: {score[0]}')\n",
    "  print(f'Test accuracy: {score[1]}')\n",
    "\n",
    "  return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0254c557-881c-4e8d-a419-a5a9c821cabd",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def training_function(model, train_set, test_set, hparams):\n",
    "    \n",
    "    model = model()\n",
    "    model.build()\n",
    "    #fitting the model and predicting\n",
    "\n",
    "    model.compile(Adam(lr=hparams['learning_rate']),'categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    #raise ValueError(list(train_set.as_numpy_iterator()))\n",
    "\n",
    "    model.fit(train_set,epochs=hparams['epochs'])\n",
    "\n",
    "    accuracy = model.evaluate(test_set)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0dfba683-4762-46bb-8d24-ead06e0f10bf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Configuring the experiment\n",
    "\n",
    "In order to use maggy distributed training, we have to configure the training model, we can pass it to TfDistributedConfig.\n",
    "the model class has to be an implementation of __tf.keras.Model__.\n",
    "We can also define __train_set__, __test_set__ and eventually the __model_parameters__. __model_parameters__ is a dictionary\n",
    "containing the parameters to be used in the \\_\\_init__ function of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a18950e-4bce-4cf0-b279-850e079973ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from maggy.experiment_config.tf_distributed import TfDistributedConfig\n",
    "\n",
    "#define the constructor parameters of your model\n",
    "model_params = {\n",
    "    #train dataset entries / num_workers\n",
    "    'train_batch_size': 75,\n",
    "    #test dataset entries / num_workers\n",
    "    'test_batch_size': 15,\n",
    "    'learning_rate': 0.04,\n",
    "    'epochs': 20,\n",
    "}\n",
    "\n",
    "training_config = TfDistributedConfig(name=\"tf_test\", model=model, train_set=train_set, test_set=test_set, process_data=process_data, hparams = model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "40fa7892-a257-48be-92e7-49172d08ac5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter added: number_layers\n"
     ]
    }
   ],
   "source": [
    "from maggy.experiment_config import OptimizationConfig\n",
    "from maggy import Searchspace\n",
    "\n",
    "# The searchspace can be instantiated with parameters\n",
    "sp = Searchspace(number_layers=('INTEGER', [2, 8]))\n",
    "\n",
    "hpo_config = OptimizationConfig(num_trials=4, optimizer=\"randomsearch\", searchspace=sp, direction=\"max\", es_interval=1, es_min=5, name=\"hp_tuning_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "40a1c764-f4df-4b66-a666-587a85bfbe3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Run distributed training\n",
    "\n",
    "Finally, we are ready to launch the maggy experiment. You just need to pass 2 parameters: the training function and the configuration variable we defined in the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8636a5d1-c330-4034-abbf-3a5e1417da95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your are running Maggy on a base configuration.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'partitionId'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-a8f37851dca2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mmaggy\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mexperiment\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexperiment\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlagom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_fn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhpo_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhpo_config\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/maggy/experiment.py\u001B[0m in \u001B[0;36mlagom\u001B[0;34m(train_fn, config)\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m         \u001B[0mdriver\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlagom_driver\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mAPP_ID\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mRUN_ID\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mLOCAL\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 83\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mdriver\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_experiment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     84\u001B[0m     \u001B[0;32mexcept\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# noqa: E722\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m         \u001B[0m_exception_handler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mseconds_to_milliseconds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mjob_start\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/maggy/core/experiment_driver/driver.py\u001B[0m in \u001B[0;36mrun_experiment\u001B[0;34m(self, train_fn)\u001B[0m\n\u001B[1;32m    140\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 142\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exp_exception_callback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    143\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m             \u001B[0;31m# Grace period to send last logs to sparkmagic.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/maggy/core/experiment_driver/optimization_driver.py\u001B[0m in \u001B[0;36m_exp_exception_callback\u001B[0;34m(self, exc)\u001B[0m\n\u001B[1;32m    156\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexception\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexception\u001B[0m  \u001B[0;31m# pylint: disable=raising-bad-type\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    159\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_patching_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_fn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mCallable\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mCallable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/maggy/core/experiment_driver/driver.py\u001B[0m in \u001B[0;36mrun_experiment\u001B[0;34m(self, train_fn)\u001B[0m\n\u001B[1;32m    131\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlocal\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m                 \u001B[0;31m# Trigger execution locally\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 133\u001B[0;31m                 \u001B[0mexecutor_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexp_json\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    134\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m                 \u001B[0;31m# Trigger execution on Spark nodes.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/maggy/core/executors/trial_executor.py\u001B[0m in \u001B[0;36m_wrapper_fun\u001B[0;34m(_)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m         \u001B[0;31m# get task context information to determine executor identifier\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 71\u001B[0;31m         \u001B[0mpartition_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtask_attempt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_partition_attempt_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     72\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m         client = rpc.Client(\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/maggy/util.py\u001B[0m in \u001B[0;36mget_partition_attempt_id\u001B[0;34m()\u001B[0m\n\u001B[1;32m     66\u001B[0m     \"\"\"\n\u001B[1;32m     67\u001B[0m     \u001B[0mtask_context\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTaskContext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 68\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtask_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpartitionId\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtask_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mattemptNumber\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'partitionId'"
     ]
    }
   ],
   "source": [
    "from maggy import experiment\n",
    "\n",
    "result = experiment.lagom(train_fn=hpo_function, config=hpo_config)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7be5d4c5-8d62-4a16-b2a8-186dc9c088b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reports at /Users/riccardo/Git Repos/maggy/examples/experiment_log/local-1620719981928/2\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Epoch 1/20\n",
      "INFO:tensorflow:Error reported to Coordinator: Layer tensorflow_model_wrapper expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'cond_1/Identity:0' shape=(None, 4) dtype=float32>, <tf.Tensor 'cond_1/Identity_1:0' shape=(None, 3) dtype=float32>]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 323, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 667, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 396, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 478, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 788, in run_step\n",
      "    outputs = model.train_step(data)\n",
      "  File \"/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 754, in train_step\n",
      "    y_pred = self(x, training=True)\n",
      "  File \"/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 993, in __call__\n",
      "    input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n",
      "  File \"/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py\", line 204, in assert_input_compatibility\n",
      "    raise ValueError('Layer ' + layer_name + ' expects ' +\n",
      "ValueError: Layer tensorflow_model_wrapper expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'cond_1/Identity:0' shape=(None, 4) dtype=float32>, <tf.Tensor 'cond_1/Identity_1:0' shape=(None, 3) dtype=float32>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py:628 _call_for_each_replica\n        return mirrored_run.call_for_each_replica(\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:93 call_for_each_replica\n        return _call_for_each_replica(strategy, fn, args, kwargs)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:234 _call_for_each_replica\n        coord.join(threads)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py:389 join\n        six.reraise(*self._exc_info_to_raise)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/six.py:703 reraise\n        raise value\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\n        yield\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:323 run\n        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:993 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:204 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer tensorflow_model_wrapper expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'cond_1/Identity:0' shape=(None, 4) dtype=float32>, <tf.Tensor 'cond_1/Identity_1:0' shape=(None, 3) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-c6a199bfc919>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mexperiment\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlagom\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraining_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining_config\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/maggy/experiment.py\u001B[0m in \u001B[0;36mlagom\u001B[0;34m(train_fn, config)\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m         \u001B[0mdriver\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlagom_driver\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mAPP_ID\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mRUN_ID\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mLOCAL\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 83\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mdriver\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_experiment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     84\u001B[0m     \u001B[0;32mexcept\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# noqa: E722\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m         \u001B[0m_exception_handler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mseconds_to_milliseconds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mjob_start\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/maggy/core/experiment_driver/driver.py\u001B[0m in \u001B[0;36mrun_experiment\u001B[0;34m(self, train_fn)\u001B[0m\n\u001B[1;32m    140\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 142\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exp_exception_callback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    143\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m             \u001B[0;31m# Grace period to send last logs to sparkmagic.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/maggy/core/experiment_driver/tf_distributed_training_driver.py\u001B[0m in \u001B[0;36m_exp_exception_callback\u001B[0;34m(self, exc)\u001B[0m\n\u001B[1;32m     95\u001B[0m                  automatically on the workers for you.\"\"\"\n\u001B[1;32m     96\u001B[0m             ) from exc\n\u001B[0;32m---> 97\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     98\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     99\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_patching_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_fn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mCallable\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mCallable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/maggy/core/experiment_driver/driver.py\u001B[0m in \u001B[0;36mrun_experiment\u001B[0;34m(self, train_fn)\u001B[0m\n\u001B[1;32m    131\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlocal\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m                 \u001B[0;31m# Trigger execution locally\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 133\u001B[0;31m                 \u001B[0mexecutor_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexp_json\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    134\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m                 \u001B[0;31m# Trigger execution on Spark nodes.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/maggy/core/executors/local_tf_dist_executor.py\u001B[0m in \u001B[0;36mwrapper_function\u001B[0;34m(_)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m                 \u001B[0mreporter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Starting training. \\n\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 84\u001B[0;31m                 retval = train_fn(\n\u001B[0m\u001B[1;32m     85\u001B[0m                     \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m                     \u001B[0mtrain_set\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain_set\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-9e2d8d128d3d>\u001B[0m in \u001B[0;36mtraining_function\u001B[0;34m(model, train_set, test_set, hparams)\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0;31m#raise ValueError(list(train_set.as_numpy_iterator()))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_set\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhparams\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'epochs'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0maccuracy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_set\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1098\u001B[0m                 _r=1):\n\u001B[1;32m   1099\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1100\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1101\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1102\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    827\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 828\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xla\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    869\u001B[0m       \u001B[0;31m# This is the first call of __call__, so we have to initialize.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    870\u001B[0m       \u001B[0minitializers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 871\u001B[0;31m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_initialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_initializers_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitializers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    872\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    873\u001B[0m       \u001B[0;31m# At this point we know that the initialization is complete (or less\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_initialize\u001B[0;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[1;32m    723\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_graph_deleter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFunctionDeleter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lifted_initializer_graph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    724\u001B[0m     self._concrete_stateful_fn = (\n\u001B[0;32m--> 725\u001B[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m    726\u001B[0m             *args, **kwds))\n\u001B[1;32m    727\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_get_concrete_function_internal_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2967\u001B[0m       \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2968\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2969\u001B[0;31m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2970\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2971\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3359\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3360\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3361\u001B[0;31m           \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3362\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3363\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3194\u001B[0m     \u001B[0marg_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbase_arg_names\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mmissing_arg_names\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3195\u001B[0m     graph_function = ConcreteFunction(\n\u001B[0;32m-> 3196\u001B[0;31m         func_graph_module.func_graph_from_py_func(\n\u001B[0m\u001B[1;32m   3197\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3198\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_python_function\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    988\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    989\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 990\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    991\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    992\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    632\u001B[0m             \u001B[0mxla_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    633\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 634\u001B[0;31m           \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    635\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    636\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    975\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    976\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 977\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    978\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    979\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py:628 _call_for_each_replica\n        return mirrored_run.call_for_each_replica(\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:93 call_for_each_replica\n        return _call_for_each_replica(strategy, fn, args, kwargs)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:234 _call_for_each_replica\n        coord.join(threads)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py:389 join\n        six.reraise(*self._exc_info_to_raise)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/six.py:703 reraise\n        raise value\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\n        yield\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:323 run\n        self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:993 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/riccardo/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:204 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer tensorflow_model_wrapper expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'cond_1/Identity:0' shape=(None, 4) dtype=float32>, <tf.Tensor 'cond_1/Identity_1:0' shape=(None, 3) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "experiment.lagom(training_function, training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "maggy-tf-dist-iris",
   "notebookOrigID": 1415393082320837,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}