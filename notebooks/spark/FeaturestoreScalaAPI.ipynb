{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>15</td><td>application_1541960591245_0046</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hopsworks0.logicalclocks.com:8088/proxy/application_1541960591245_0046/\">Link</a></td><td><a target=\"_blank\" href=\"http://hopsworks0.logicalclocks.com:8042/node/containerlogs/container_e01_1541960591245_0046_01_000001/test__meb10000\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "import io.hops.util.Hops\n"
     ]
    }
   ],
   "source": [
    "import io.hops.util.Hops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Project Featurestore\n",
    "\n",
    "Each project with the featurestore enabled gets its own Hive database for the featurestore, the name of the featurestore database is 'projectname_featurestore' and can be retrieved from the hops-util-py featurestore API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1: String = test_featurestore\n"
     ]
    }
   ],
   "source": [
    "Hops.getProjectFeaturestore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all Featurestores Accessible in the Current Project\n",
    "\n",
    "Feature stores can be shared across projects just like other Hopsworks datasets. You can use this API function to list all the featurestores accessible in the project programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res2: java.util.List[String] = [test_featurestore]\n"
     ]
    }
   ],
   "source": [
    "Hops.getProjectFeaturestores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Individual Feature\n",
    "\n",
    "When retrieving a single feature from the featurestore, the hops-util-py library will infer which featuregroup the feature belongs to by querying the metastore, but you can also explicitly specify which featuregroup and version to query. If there are multiple features of the same name in the featurestore, it is required to specify enough information to uniquely identify the feature (e.g which featuregroup and which version).  If no featurestore is provided it will default to the project's featurestore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without specifying featuregroup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|action|\n",
      "+------+\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hops.getFeature(spark, \"action\", Hops.getProjectFeaturestore).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With specifed featuregroup and version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|action|\n",
      "+------+\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hops.getFeature(spark, \"action\", Hops.getProjectFeaturestore, \"web_logs_features\", 1).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Featuregroup\n",
    "\n",
    "You can get an entire featuregroup from the API. If no featurestore is provided the API will default to the project's featurestore, if no version is provided it will default to version 1 of the featuregroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+---------+---------+\n",
      "|cust_id|  min_trx|  max_trx|  avg_trx|count_trx|\n",
      "+-------+---------+---------+---------+---------+\n",
      "|    148| 390.4109|2094.9958| 1090.509|       16|\n",
      "|    496| 9.235389|1464.5397| 738.1404|       16|\n",
      "|    463|33.797318|1828.2426|899.89594|       30|\n",
      "|    471|578.16833|636.18713|607.17773|        4|\n",
      "|    243|119.73669| 1582.427| 698.5791|       28|\n",
      "+-------+---------+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hops.getFeaturegroup(spark, \"trx_summary_features\", Hops.getProjectFeaturestore, 1).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Set of Features\n",
    "\n",
    "When retrieving a list of features from the featurestore, the hops-util-py library will infer which featuregroup the features belongs to by querying the metastore. If the features reside in different featuregroups, the library will also **try** to infer how to join the features together based on common columns. If the JOIN query cannot be inferred due to existence of multiple features with the same name or non-obvious JOIN query, the user need to supply enough information to the API call to be able to query the featurestore. If the user already knows the JOIN query it can also run `Hops.queryFeaturestore(joinQuery)` directly (an example of using this approach is shown further down in this notebook). If no featurestore is provided it will default to the project's featurestore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import scala.collection.JavaConversions._\n",
      "features: List[String] = List(pagerank, triangle_count, avg_trx)\n"
     ]
    }
   ],
   "source": [
    "import scala.collection.JavaConversions._\n",
    "val features = List(\"pagerank\", \"triangle_count\", \"avg_trx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+---------+\n",
      "|pagerank|triangle_count|  avg_trx|\n",
      "+--------+--------------+---------+\n",
      "|     1.0|           3.0|963.64233|\n",
      "|     1.0|          12.0| 746.5783|\n",
      "|     1.0|           7.0|687.91376|\n",
      "|     1.0|          12.0| 732.6695|\n",
      "|     1.0|           4.0|  641.785|\n",
      "+--------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hops.getFeatures(spark, features, Hops.getProjectFeaturestore).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without specifying the join key but specifying featuregroups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featuregroupsMap: scala.collection.immutable.Map[String,Integer] = Map(trx_graph_summary_features -> 1, trx_summary_features -> 1)\n",
      "javaFeaturegroupsMap: java.util.HashMap[String,Integer] = {trx_summary_features=1, trx_graph_summary_features=1}\n"
     ]
    }
   ],
   "source": [
    "val featuregroupsMap = Map[String, Integer](\"trx_graph_summary_features\"->1,\"trx_summary_features\"->1)\n",
    "val javaFeaturegroupsMap = new java.util.HashMap[String, Integer](featuregroupsMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+---------+\n",
      "|pagerank|triangle_count|  avg_trx|\n",
      "+--------+--------------+---------+\n",
      "|     1.0|           3.0|963.64233|\n",
      "|     1.0|          12.0| 746.5783|\n",
      "|     1.0|           7.0|687.91376|\n",
      "|     1.0|          12.0| 732.6695|\n",
      "|     1.0|           4.0|  641.785|\n",
      "+--------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hops.getFeatures(spark, features, Hops.getProjectFeaturestore, javaFeaturegroupsMap).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying both featuregroups and join key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+---------+\n",
      "|pagerank|triangle_count|  avg_trx|\n",
      "+--------+--------------+---------+\n",
      "|     1.0|           3.0|963.64233|\n",
      "|     1.0|          12.0| 746.5783|\n",
      "|     1.0|           7.0|687.91376|\n",
      "|     1.0|          12.0| 732.6695|\n",
      "|     1.0|           4.0|  641.785|\n",
      "+--------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hops.getFeatures(spark, features, Hops.getProjectFeaturestore, javaFeaturegroupsMap, \"cust_id\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting 10 features from two different featuregroups without specifying the featuregroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features1: List[String] = List(pagerank, triangle_count, avg_trx, count_trx, max_trx, min_trx, balance, birthdate, join_date, number_of_accounts)\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+\n",
      "|pagerank|triangle_count|  avg_trx|count_trx|  max_trx|  min_trx|  balance|          birthdate|          join_date|number_of_accounts|\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+\n",
      "|     1.0|           5.0| 1090.509|       16|2094.9958| 390.4109|12920.496|2003-04-12 00:00:00|1998-09-06 00:00:00|                10|\n",
      "|     1.0|           5.0| 738.1404|       16|1464.5397| 9.235389| 11096.28|1985-09-14 00:00:00|2016-07-06 00:00:00|                 7|\n",
      "|     1.0|           6.0|899.89594|       30|1828.2426|33.797318|1868.0168|2006-09-07 00:00:00|1973-02-13 00:00:00|                14|\n",
      "|     1.0|           4.0|607.17773|        4|636.18713|578.16833| 9278.589|2018-07-10 00:00:00|1999-02-25 00:00:00|                 1|\n",
      "|     1.0|           9.0| 698.5791|       28| 1582.427|119.73669| 593.9806|1979-04-12 00:00:00|2017-12-07 00:00:00|                11|\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val features1 = List(\"pagerank\", \"triangle_count\", \"avg_trx\", \"count_trx\", \"max_trx\", \"min_trx\", \"balance\", \"birthdate\", \"join_date\", \"number_of_accounts\")\n",
    "Hops.getFeatures(spark, features1, Hops.getProjectFeaturestore).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to get features that exist in multiple featuregroups, the library will not be able to infer from which featuregroup to get the features, so you must specify the featuregroups explicitly as an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "java.lang.IllegalArgumentException: Found the feature with name: pep in more than one of the featuregroups of the featurestore test_featurestore please specify featuregroup that you want to get the feature from. The matched featuregroups are: pep_lookup_1, customer_type_lookup_1, gender_lookup_1, trx_type_lookup_1, country_lookup_1, industry_sector_lookup_1, alert_type_lookup_1, rule_name_lookup_1, web_address_lookup_1, browser_action_lookup_1, demographic_features_1, trx_graph_edge_list_1, trx_graph_summary_features_1, trx_features_1, trx_summary_features_1, hipo_features_1, alert_features_1, police_report_features_1, web_logs_features_1\n",
      "  at io.hops.util.featurestore.FeaturestoreHelper.findFeature(FeaturestoreHelper.java:177)\n",
      "  at io.hops.util.featurestore.FeaturestoreHelper.findFeaturegroupsThatContainsFeatures(FeaturestoreHelper.java:134)\n",
      "  at io.hops.util.Hops.getFeatures(Hops.java:1231)\n",
      "  ... 52 elided\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val features2 = List(\"pagerank\", \"triangle_count\", \"avg_trx\", \"count_trx\", \"max_trx\", \"min_trx\", \"balance\", \"birthdate\", \"join_date\", \"number_of_accounts\", \"pep\")\n",
    "Hops.getFeatures(spark, features2, Hops.getProjectFeaturestore).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we specify the featuregroup to get the feature that exists in multiple featuregroups, the library can infer how to get the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featuregroupsMap1: scala.collection.immutable.Map[String,Integer] = Map(trx_graph_summary_features -> 1, trx_summary_features -> 1, demographic_features -> 1)\n",
      "javaFeaturegroupsMap1: java.util.HashMap[String,Integer] = {demographic_features=1, trx_summary_features=1, trx_graph_summary_features=1}\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+-------------+\n",
      "|pagerank|triangle_count|  avg_trx|count_trx|  max_trx|  min_trx|  balance|          birthdate|          join_date|number_of_accounts|          pep|\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+-------------+\n",
      "|     1.0|           5.0| 1090.509|       16|2094.9958| 390.4109|12920.496|2003-04-12 00:00:00|1998-09-06 00:00:00|                10| 309237645312|\n",
      "|     1.0|           5.0| 738.1404|       16|1464.5397| 9.235389| 11096.28|1985-09-14 00:00:00|2016-07-06 00:00:00|                 7|1331439861760|\n",
      "|     1.0|           6.0|899.89594|       30|1828.2426|33.797318|1868.0168|2006-09-07 00:00:00|1973-02-13 00:00:00|                14| 309237645312|\n",
      "|     1.0|           4.0|607.17773|        4|636.18713|578.16833| 9278.589|2018-07-10 00:00:00|1999-02-25 00:00:00|                 1| 309237645312|\n",
      "|     1.0|           9.0| 698.5791|       28| 1582.427|119.73669| 593.9806|1979-04-12 00:00:00|2017-12-07 00:00:00|                11|1331439861760|\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val featuregroupsMap1 = Map[String, Integer](\n",
    "    \"trx_graph_summary_features\"->1,\n",
    "    \"trx_summary_features\"->1,\n",
    "    \"demographic_features\" ->1\n",
    ")\n",
    "val javaFeaturegroupsMap1 = new java.util.HashMap[String, Integer](featuregroupsMap1)\n",
    "Hops.getFeatures(spark, features2, Hops.getProjectFeaturestore, javaFeaturegroupsMap1).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of getting 19 features from 5 different featuregroups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features3: List[String] = List(pagerank, triangle_count, avg_trx, count_trx, max_trx, min_trx, balance, birthdate, join_date, number_of_accounts, pep, customer_type, gender, web_id, time_spent_seconds, address, action, report_date, report_id)\n",
      "featuregroupsMap2: scala.collection.immutable.Map[String,Integer] = Map(police_report_features -> 1, web_logs_features -> 1, trx_graph_summary_features -> 1, trx_summary_features -> 1, demographic_features -> 1)\n",
      "javaFeaturegroupsMap2: java.util.HashMap[String,Integer] = {demographic_features=1, police_report_features=1, web_logs_features=1, trx_summary_features=1, trx_graph_summary_features=1}\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+------------+-------------+------------+------+------------------+-------+------+-------------------+---------+\n",
      "|pagerank|triangle_count|  avg_trx|count_trx|  max_trx|  min_trx|  balance|          birthdate|          join_date|number_of_accounts|         pep|customer_type|      gender|web_id|time_spent_seconds|address|action|        report_date|report_id|\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+------------+-------------+------------+------+------------------+-------+------+-------------------+---------+\n",
      "|     1.0|           1.0|599.04565|       18|1283.6562|36.825226|15603.314|1995-05-13 00:00:00|2015-01-01 00:00:00|                14|309237645312| 420906795008|566935683072|  4756|               300|      0|     0|2011-03-26 00:00:00|        1|\n",
      "|     1.0|           1.0|599.04565|       18|1283.6562|36.825226|15603.314|1995-05-13 00:00:00|2015-01-01 00:00:00|                14|309237645312| 420906795008|566935683072|  3517|               762|      1|     0|2011-03-26 00:00:00|        1|\n",
      "|     1.0|           1.0|599.04565|       18|1283.6562|36.825226|15603.314|1995-05-13 00:00:00|2015-01-01 00:00:00|                14|309237645312| 420906795008|566935683072|  1996|               271|      0|     0|2011-03-26 00:00:00|        1|\n",
      "|     1.0|           1.0|599.04565|       18|1283.6562|36.825226|15603.314|1995-05-13 00:00:00|2015-01-01 00:00:00|                14|309237645312| 420906795008|566935683072|  1342|               197|      0|     0|2011-03-26 00:00:00|        1|\n",
      "|     1.0|           1.0|599.04565|       18|1283.6562|36.825226|15603.314|1995-05-13 00:00:00|2015-01-01 00:00:00|                14|309237645312| 420906795008|566935683072|  1278|               102|      1|     0|2011-03-26 00:00:00|        1|\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+------------+-------------+------------+------+------------------+-------+------+-------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val features3 = List(\"pagerank\", \"triangle_count\", \"avg_trx\", \"count_trx\", \"max_trx\", \"min_trx\",\n",
    "    \"balance\", \"birthdate\", \"join_date\", \"number_of_accounts\", \"pep\", \"customer_type\", \"gender\", \"web_id\",\n",
    "    \"time_spent_seconds\", \"address\", \"action\", \"report_date\", \"report_id\")\n",
    "val featuregroupsMap2 = Map[String, Integer](\n",
    "    \"trx_graph_summary_features\"->1,\n",
    "    \"trx_summary_features\"->1,\n",
    "    \"demographic_features\" ->1,\n",
    "    \"web_logs_features\" -> 1,\n",
    "    \"police_report_features\" -> 1\n",
    ")\n",
    "val javaFeaturegroupsMap2 = new java.util.HashMap[String, Integer](featuregroupsMap2)\n",
    "Hops.getFeatures(spark, features3, Hops.getProjectFeaturestore, javaFeaturegroupsMap2).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you might want to get a feature that exist in multiple featuregroups and you want to include all of these featuregroups in your query, then you can specify from which of the featuregroup to get the feature by prepending the feature-name with the featuregroup name + '_version', e.g: 'demographic_features_1.cust_id'. If you don't specify this the query will fail as the library won't know from which of your specified featuregroups to get the feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "org.apache.spark.sql.AnalysisException: Reference 'cust_id' is ambiguous, could be: demographic_features_1.cust_id, police_report_features_1.cust_id, web_logs_features_1.cust_id, trx_summary_features_1.cust_id, trx_graph_summary_features_1.cust_id.; line 1 pos 219\n",
      "  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolve(LogicalPlan.scala:213)\n",
      "  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveChildren(LogicalPlan.scala:97)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$37.apply(Analyzer.scala:826)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$37.apply(Analyzer.scala:828)\n",
      "  at org.apache.spark.sql.catalyst.analysis.package$.withPosition(package.scala:53)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveReferences$$resolve(Analyzer.scala:825)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$9$$anonfun$applyOrElse$36.apply(Analyzer.scala:895)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$9$$anonfun$applyOrElse$36.apply(Analyzer.scala:895)\n",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\n",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\n",
      "  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:106)\n",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:118)\n",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$1.apply(QueryPlan.scala:122)\n",
      "  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n",
      "  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n",
      "  at scala.collection.immutable.List.foreach(List.scala:392)\n",
      "  at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n",
      "  at scala.collection.immutable.List.map(List.scala:296)\n",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:122)\n",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:127)\n",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n",
      "  at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:127)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$9.applyOrElse(Analyzer.scala:895)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$9.applyOrElse(Analyzer.scala:837)\n",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$2.apply(TreeNode.scala:293)\n",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$2.apply(TreeNode.scala:293)\n",
      "  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:292)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$.apply(Analyzer.scala:837)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$.apply(Analyzer.scala:690)\n",
      "  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n",
      "  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n",
      "  at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n",
      "  at scala.collection.immutable.List.foldLeft(List.scala:84)\n",
      "  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n",
      "  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n",
      "  at scala.collection.immutable.List.foreach(List.scala:392)\n",
      "  at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:124)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:118)\n",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:103)\n",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n",
      "  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:74)\n",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)\n",
      "  at io.hops.util.featurestore.FeaturestoreHelper.logAndRunSQL(FeaturestoreHelper.java:400)\n",
      "  at io.hops.util.featurestore.FeaturestoreHelper.getFeatures(FeaturestoreHelper.java:333)\n",
      "  at io.hops.util.Hops.getFeatures(Hops.java:1196)\n",
      "  ... 52 elided\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val features4 = List(\"pagerank\", \"triangle_count\", \"avg_trx\", \"count_trx\", \"max_trx\", \"min_trx\",\n",
    "    \"balance\", \"birthdate\", \"join_date\", \"number_of_accounts\", \"pep\", \"customer_type\", \"gender\", \"web_id\",\n",
    "    \"time_spent_seconds\", \"address\", \"action\", \"report_date\", \"report_id\", \"cust_id\")\n",
    "Hops.getFeatures(spark, features4, Hops.getProjectFeaturestore, javaFeaturegroupsMap2).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change 'cust_id' to 'featuregroupname_version.cust_id' the library knows where to get the feature from and the query works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features5: List[String] = List(pagerank, triangle_count, avg_trx, count_trx, max_trx, min_trx, balance, birthdate, join_date, number_of_accounts, pep, customer_type, gender, web_id, time_spent_seconds, address, action, report_date, report_id, demographic_features_1.cust_id)\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+------------+-------------+------------+------+------------------+-------+------+-------------------+---------+-------+\n",
      "|pagerank|triangle_count|  avg_trx|count_trx|  max_trx|  min_trx|  balance|          birthdate|          join_date|number_of_accounts|         pep|customer_type|      gender|web_id|time_spent_seconds|address|action|        report_date|report_id|cust_id|\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+------------+-------------+------------+------+------------------+-------+------+-------------------+---------+-------+\n",
      "|     1.0|           1.0|599.04565|       18|1283.6562|36.825226|15603.314|1995-05-13 00:00:00|2015-01-01 00:00:00|                14|309237645312| 420906795008|566935683072|  4756|               300|      0|     0|2011-03-26 00:00:00|        1|      9|\n",
      "|     1.0|           1.0|599.04565|       18|1283.6562|36.825226|15603.314|1995-05-13 00:00:00|2015-01-01 00:00:00|                14|309237645312| 420906795008|566935683072|  3517|               762|      1|     0|2011-03-26 00:00:00|        1|      9|\n",
      "|     1.0|           1.0|599.04565|       18|1283.6562|36.825226|15603.314|1995-05-13 00:00:00|2015-01-01 00:00:00|                14|309237645312| 420906795008|566935683072|  1996|               271|      0|     0|2011-03-26 00:00:00|        1|      9|\n",
      "|     1.0|           1.0|599.04565|       18|1283.6562|36.825226|15603.314|1995-05-13 00:00:00|2015-01-01 00:00:00|                14|309237645312| 420906795008|566935683072|  1342|               197|      0|     0|2011-03-26 00:00:00|        1|      9|\n",
      "|     1.0|           1.0|599.04565|       18|1283.6562|36.825226|15603.314|1995-05-13 00:00:00|2015-01-01 00:00:00|                14|309237645312| 420906795008|566935683072|  1278|               102|      1|     0|2011-03-26 00:00:00|        1|      9|\n",
      "+--------+--------------+---------+---------+---------+---------+---------+-------------------+-------------------+------------------+------------+-------------+------------+------+------------------+-------+------+-------------------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val features5 = List(\"pagerank\", \"triangle_count\", \"avg_trx\", \"count_trx\", \"max_trx\", \"min_trx\",\n",
    "    \"balance\", \"birthdate\", \"join_date\", \"number_of_accounts\", \"pep\", \"customer_type\", \"gender\", \"web_id\",\n",
    "    \"time_spent_seconds\", \"address\", \"action\", \"report_date\", \"report_id\", \"demographic_features_1.cust_id\")\n",
    "Hops.getFeatures(spark, features5, Hops.getProjectFeaturestore, javaFeaturegroupsMap2).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Text Query from Feature Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For complex queries that cannot be inferred by the helper functions, enter the sql directly to the method `Hops.queryFeaturestore()` it will default to the project specific feature store but you can also specify it explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without specifying the featurestore it will default to the project-specific featurestore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------+\n",
      "|cust_id|pagerank|triangle_count|\n",
      "+-------+--------+--------------+\n",
      "|     29|     1.0|          12.0|\n",
      "|    474|     1.0|           7.0|\n",
      "|     65|     1.0|          12.0|\n",
      "|    222|     1.0|          13.0|\n",
      "|    270|     1.0|           8.0|\n",
      "+-------+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hops.queryFeaturestore(\n",
    "    spark,\n",
    "    \"SELECT * FROM trx_graph_summary_features_1 WHERE triangle_count > 5\",\n",
    "    null\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify the featurestore to query explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------+\n",
      "|cust_id|pagerank|triangle_count|\n",
      "+-------+--------+--------------+\n",
      "|     29|     1.0|          12.0|\n",
      "|    474|     1.0|           7.0|\n",
      "|     65|     1.0|          12.0|\n",
      "|    222|     1.0|          13.0|\n",
      "|    270|     1.0|           8.0|\n",
      "+-------+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hops.queryFeaturestore(\n",
    "    spark,\n",
    "    \"SELECT * FROM trx_graph_summary_features_1 WHERE triangle_count > 5\",\n",
    "    Hops.getProjectFeaturestore\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to the Feature Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first get some sample data to insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleDataMap: scala.collection.immutable.Map[String,Int] = Map(hops_customer_1 -> 3, hops_customer_2 -> 4)\n",
      "sampleDataDf: org.apache.spark.sql.DataFrame = [customer_type: string, id: int]\n"
     ]
    }
   ],
   "source": [
    "val sampleDataMap = Map(\"hops_customer_1\"-> 3, \"hops_customer_2\"-> 4)\n",
    "val sampleDataDf = sampleDataMap.toSeq.toDF(\"customer_type\", \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+\n",
      "|  customer_type| id|\n",
      "+---------------+---+\n",
      "|hops_customer_1|  3|\n",
      "|hops_customer_2|  4|\n",
      "+---------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampleDataDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets inspect the contents of the featuregroup 'customer_type_lookup' that we are going to insert the sample data into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparkDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [customer_type: string, id: bigint]\n"
     ]
    }
   ],
   "source": [
    "val sparkDf = Hops.getFeaturegroup(spark, \"customer_type_lookup\", Hops.getProjectFeaturestore, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|customer_type|          id|\n",
      "+-------------+------------+\n",
      "|    corporate|420906795008|\n",
      "|      private|893353197568|\n",
      "+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res19: Long = 2\n"
     ]
    }
   ],
   "source": [
    "sparkDf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can insert the sample data and verify the new contents of the featuregroup. By default the insert mode is \"append\", the featurestore is the project's featurestore and the version is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hops.insertIntoFeaturegroup(\n",
    "    sampleDataDf, \n",
    "    spark, \n",
    "    \"customer_type_lookup\",\n",
    "    Hops.getProjectFeaturestore,\n",
    "    1,\n",
    "    \"append\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+\n",
      "|  customer_type|          id|\n",
      "+---------------+------------+\n",
      "|hops_customer_1|           3|\n",
      "|hops_customer_2|           4|\n",
      "|      corporate|420906795008|\n",
      "|        private|893353197568|\n",
      "+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hops.getFeaturegroup(spark, \"customer_type_lookup\", Hops.getProjectFeaturestore, 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res22: Long = 4\n"
     ]
    }
   ],
   "source": [
    "Hops.getFeaturegroup(spark, \"customer_type_lookup\", Hops.getProjectFeaturestore, 1).count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two supported insert modes are \"append\" and \"overwrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hops.insertIntoFeaturegroup(\n",
    "    sampleDataDf, \n",
    "    spark, \n",
    "    \"customer_type_lookup\",\n",
    "    Hops.getProjectFeaturestore,\n",
    "    1,\n",
    "    \"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+\n",
      "|  customer_type| id|\n",
      "+---------------+---+\n",
      "|hops_customer_1|  3|\n",
      "|hops_customer_2|  4|\n",
      "+---------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hops.getFeaturegroup(spark, \"customer_type_lookup\", Hops.getProjectFeaturestore, 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res25: Long = 2\n"
     ]
    }
   ],
   "source": [
    "Hops.getFeaturegroup(spark, \"customer_type_lookup\", Hops.getProjectFeaturestore, 1).count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Featurestore Metadata\n",
    "To explore the contents of the featurestore we recommend using the featurestore page in the Hopsworks UI but you can also get the metadata programmatically from the REST API with the following method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res26: java.util.List[io.hops.util.featurestore.FeaturegroupDTO] = [io.hops.util.featurestore.FeaturegroupDTO@448bc589, io.hops.util.featurestore.FeaturegroupDTO@780247f0, io.hops.util.featurestore.FeaturegroupDTO@40ec1f32, io.hops.util.featurestore.FeaturegroupDTO@35b297a6, io.hops.util.featurestore.FeaturegroupDTO@2f0fab14, io.hops.util.featurestore.FeaturegroupDTO@45d844c2, io.hops.util.featurestore.FeaturegroupDTO@65edd6c4, io.hops.util.featurestore.FeaturegroupDTO@44c37278, io.hops.util.featurestore.FeaturegroupDTO@164626ff, io.hops.util.featurestore.FeaturegroupDTO@113f9ea1, io.hops.util.featurestore.FeaturegroupDTO@1a6f31b4, io.hops.util.featurestore.FeaturegroupDTO@4560d033, io.hops.util.featurestore.FeaturegroupDTO@62b677be, io.hops.util.featurestore.FeaturegroupDTO@f9137df, io..."
     ]
    }
   ],
   "source": [
    "Hops.getFeaturestoreMetadata(Hops.getProjectFeaturestore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
