{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Partitioning Via Pagerank\n",
    "date: 2018-06-04\n",
    "type: technical_note\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the Small example curated [at this site](https://lintool.github.io/Cloud9/docs/exercises/pagerank.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.textFile('../data/pagerank.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of data has a page in the 0th index, and all of the pages it links to in the rest of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['9465097', '12566713', '11158207', '11145916', '11883199', '12857908'],\n",
       " ['11581419', '11287582', '9420209', '8709207', '11160736', '12610128'],\n",
       " ['8553535', '8709207', '12518224', '11044077', '9650960', '11886254'],\n",
       " ['7778283', '8709207', '8601783', '7494284', '9298727', '8973339'],\n",
       " ['11044077', '12518224', '9568045', '8553535', '9784363', '9650960']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = rdd.map(lambda x: x.split())\n",
    "pages.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough, it has 93 rows. One for each page in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages.map(lambda x: x[0]).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to capture the neighboring relationships as a list of tuples of the form `(host page, neighbor list)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9465097', ['12566713', '11158207', '11145916', '11883199', '12857908'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = pages.map(lambda x: (x[0], x[1:]))\n",
    "neighbors.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And initialize each page's rank to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('9465097', 1), ('11581419', 1), ('8553535', 1), ('7778283', 1), ('11044077', 1)]\n"
     ]
    }
   ],
   "source": [
    "ranks = neighbors.map(lambda x: (x[0], 1))\n",
    "print(ranks.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Iterating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On each iteration of PageRank, we want to *send a contribution* from the host node to each of its neighbors equal to\n",
    "\n",
    "```\n",
    "rank(p)/numNeighbors(p)\n",
    "```\n",
    "\n",
    "And then set each page's rank equal `0.15 + 0.85 * contributionsReceived`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('12857908',\n",
       "  (['11878901', '10233949', '12050360', '11602792', '11163673'], 1)),\n",
       " ('8957669', (['8957670', '9234794', '11145916', '9650960', '10573627'], 1)),\n",
       " ('8151305', (['7494284', '8825715', '9650960', '11160736', '9032384'], 1)),\n",
       " ('11886254', (['12518224', '12857908', '8553535', '11878901', '9650960'], 1)),\n",
       " ('12033775', (['9784363', '11287582', '8709207', '11044077', '10873782'], 1))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors.join(ranks).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpack_row(row):\n",
    "    pageID, (links, rank) = row\n",
    "    yield from map(lambda dest: (dest, rank / len(links)), links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    contributions = neighbors.join(ranks).flatMap(unpack_row)\n",
    "    ranks = contributions.reduceByKey(lambda x, y: x + y).mapValues(lambda x: 0.15 + 0.85 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 53s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "result = ranks.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning this with Intentional Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type was `pages`? `neighbors`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pyspark.rdd.PipelinedRDD, pyspark.rdd.PipelinedRDD)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pages), type(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both were `RDDs`, **meaning** that each time we utilized them, they were potentially getting shuffled across the network despite never changing.\n",
    "\n",
    "If we instead did the same implementation, but *persisted* the parts that didn't change, what kind of performance boost will we see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[130] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = rdd.map(lambda x: x.split())\n",
    "pages.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[131] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = pages.map(lambda x: (x[0], x[1:]))\n",
    "neighbors.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranks = pages.map(lambda x: (x[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    contributions = neighbors.join(ranks).flatMap(unpack_row)\n",
    "    ranks = contributions.reduceByKey(lambda x, y: x + y).mapValues(lambda x: 0.15 + 0.85 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 51s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "result = ranks.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eureka! **2 seconds of performance boost**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure why this was a bust.\n",
    "\n",
    "Was there something I could have done? Or was it merely a limitation of running on a regular old computer?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
